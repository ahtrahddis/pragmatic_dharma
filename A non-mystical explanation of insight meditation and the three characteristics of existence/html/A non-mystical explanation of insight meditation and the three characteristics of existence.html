<!DOCTYPE html>
<html style="">
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  </head>
  <body>
    <div>
      <h1 id="Introduction">Preface</h1>
      <p>This e-book is an unofficial collection of texts written by <a href="https://kajsotala.fi/">Kaj
          Sotala</a> and published on <a href="https://www.lesswrong.com/">LESSWRONG</a>.</p>
      <h1>Introduction</h1>
      <p>Insight meditation, enlightenment, what’s that all about? </p>
      <p>The sequence of posts starting from this one is my personal attempt at
        answering that question. It grew out of me being annoyed about so much
        of this material seeming to be straightforwardly explainable in
        non-mysterious terms, but me also being unable to find any book or
        article that would do this to my satisfaction. In particular, I wanted
        something that would:</p>
      <ul>
        <li>Explain what kinds of implicit assumptions build up our default
          understanding of reality and how those assumptions are subtly flawed.
          It would then point out aspects from our experience whose repeated
          observation will update those assumptions, and explain how this may
          cause psychological change in someone who meditates.</li>
        <li>It would also explain how the so-called “<u><span><span><span><a href="https://en.wikipedia.org/wiki/Three_marks_of_existence">three
                    characteristics of existence</a></span></span></span></u>”
          of Buddhism - impermanence, no-self and unsatisfactoriness - are all
          interrelated and connected with each other in a way your average
          Western science-minded, allergic-to-mysticism reader can understand. </li>
      </ul>
      <p>I failed to find a resource that would do this in the way I had in
        mind, so then I wrote one myself.</p>
      <p>From the onset, I want to note that I am calling this <em>a</em>
        non-mystical take on the three characteristics, rather than <em>the</em>
        non-mystical take on the three characteristics. This is an attempt to
        explain what I personally think is going on, and to sketch out an
        explanation of how various experiences and Buddhist teachings <em>could</em>
        be understandable in straightforward terms. I don’t expect this to be
        anything like a complete or perfect explanation, but rather one
        particular model that might be useful.</p>
      <p>The main intent of this series is summarized by a <u><span><span><a class="CommentLinkPreviewWithComment-link"
                href="https://www.lesswrong.com/posts/tMhEv28KJYWsu6Wdo/kensh?commentId=eYyHWAZ4yfC9o94zW">comment
                written by Vanessa Kosoy</a></span></span></u>, justifiably
        skeptical of grandiose claims about enlightenment that are made without
        further elaboration on the actual mechanisms of it:</p>
      <blockquote>I think that the only coherent way to convince us that
        Enlightenment is real is to provide a model from a 3rd party
        perspective. [...] The model doesn't have to be fully mathematically
        rigorous: as always, it can be a little fuzzy and informal. However, it
        must be precise enough in order to (i) correctly capture the essentials
        and (ii) be interpretable more or less unambiguously by the sufficiently
        educated reader.</blockquote>
      <blockquote>Now, having such a model doesn't mean you can actually
        reproduce Enlightenment itself. [...] However, producing such a model
        would give us the enormous advantages of (i) being able to come up with
        experimental tests for the model (ii) understanding what sort of
        advantages we would gain by reaching Enlightenment (iii) being sure that
        your are talking about something that is at least a coherent possible
        world even if we are still unsure whether you are describing the actual
        world.</blockquote>
      <p>I hope to at least put together a starting point for a model that would
        fulfill those criteria.</p>
      <p>Note that these articles are <em>not</em> saying “you should
        meditate”. Getting deep in meditation requires a huge investment of time
        and effort - though smaller investments are also likely to produce
        benefits - and is associated with its own risks [<span><span><span><a href="https://www.theatlantic.com/health/archive/2014/06/the-dark-knight-of-the-souls/372766/">1</a></span></span></span>
        <span><span><span><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0176239">2</a></span></span></span>
        <span><span><span><a href="https://www.mctb.org/mctb2/table-of-contents/part-vi-my-spiritual-quest/61-crazy/">3</a></span></span></span>
        <span><span><span><a href="https://www.facebook.com/Xuenay/posts/10158478256833662">4</a></span></span></span>].
        My intent is merely to discuss some of the mechanisms involved in
        meditation and the mind. Whether one should get direct acquaintance with
        them is a separate question that goes beyond the scope of this
        discussion.</p>
      <h2 id="Briefly_on_the_mechanisms_of_meditation">Briefly on the mechanisms
        of meditation</h2>
      <p>In a previous article, <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/WYmmC3W6ZNhEgAmWG/a-mechanistic-model-of-meditation">A
                Mechanistic Model of Meditation</a></span></span></u>, I argued
        that it is possible in principle for meditation to give people an
        improved understanding of the way their mind operates. </p>
      <p>To briefly recap my argument: we know it is possible for people to
        train their senses, such as learning to notice more details or make more
        fine-grained sensory discriminations. One theory is that those details
        have always been processed in the brain, but the information has not
        made it to the higher stages of the processing hierarchy. As you
        repeatedly focus your attention to a particular kind of pattern in your
        consciousness, neurons re-orient to strengthen that pattern and build
        connections to the lower-level circuits from which it emerges. This
        re-encodes the information in those circuits in a format which can be
        represented in consciousness. </p>
      <p>This means at least some kinds of sensory training are <em>training in
          introspection </em>- learning to better access information which
        already exists in your brain. This implies you can also learn to
        strengthen <em>other</em> patterns in your consciousness, especially if
        you have some source of feedback that you can use to guide the training.
      </p>
      <p>I gave an example of experiential forms of therapy doing exactly this,
        and then described how a particular style of meditation used one’s
        awareness of the breath as an objective feedback signal for developing
        increased “introspective awareness” of one’s own mind.</p>
      <p>That post was mostly describing the ways in which meditation can be
        used to become more aware of the <em>content</em> of your thoughts.
        However, in observing the content, it is hard to avoid noticing at least
        some of the <em>structure</em> of the thought process as well. </p>
      <p>For example, you might try to follow your breath and think you are
        doing a good job. In this case, there are at least two kinds of content
        in your mind: the actual sensory experience of the breath, and thoughts
        about how badly or well you are doing. The latter might take the form of
        e.g. mental dialogue that says things like "I'm still managing to follow
        my breath". Now, since you may find it rewarding to just think that you
        are meditating well, <em>that thought</em> may start to become
        rewarded, and you may find yourself repeatedly <em>thinking</em> that
        you are successfully following the breath... even as the thought of “I
        am meditating well” has become self-sustaining and no longer connected
        to whether you are following the breath or not.</p>
      <p>Eventually you will realize that you have actually been <em>thinking
          about following the breath</em> rather than <em>actually following
          it. </em>This is a minor insight into the way that your thought
        processes are structured, revealing it is possible for sensations and
        thoughts about sensations to become mixed up.</p>
      <p>It is also possible to practice meditation in a way which explicitly
        focuses on investigating structure. We can make an analogy to looking at
        a painting. (Thanks to Alexei Andreev for suggesting this analogy.) Seen
        from some distance, a painting has "content": it depicts things like
        people, buildings, boats and so forth. But when you get closer to it and
        look carefully, you can see that all the content is composed of things
        like brush strokes, individual colored shapes, paint of varying
        thickness, and so on. This is "structure". While all types of meditation
        are going to reveal <em>something</em> about structure, there are also
        types of meditation which are specifically aimed at exploring it.
        Meditation which focuses on investigating structure is commonly called <em>insight</em>
        meditation. </p>
      <h2 id="Investigating_the_mind_vs__investigating_reality">Investigating
        the mind vs. investigating reality</h2>
      <p>Now, it is worth noting that these practices are not always framed in
        terms of "investigating the structure of the mind", nor does the actual
        experience of doing them necessarily feel like that. Rather, the framing
        and experience is commonly that of investigating the nature of <em>reality</em>.</p>
      <p>For example, in <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/mELQFMi9egPn5EAjK/my-attempt-to-explain-looking-insight-meditation-and">an
                earlier article</a></span></span></u> trying to explain insight
        meditation, I mentioned I had once had the thought that I could never be
        happy. When I paid closer attention to why I thought that, I noticed
        that my mental image of a happy person included strong extraversion,
        which conflicted with the self-image that I had of myself as an
        introvert. After I noticed the happiness-extraversion connection, it
        became apparent that I could be happy even as an introvert, and the
        original thought disappeared. (Although I didn't know it at the time, <u><span><span><a
                class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain">it
                is common for emotional beliefs to change</a></span></span></u>
        when they become explicit enough for the brain to notice them being
        erroneous.)</p>
      <p>Essentially, I had originally believed “I can never be happy”, and this
        belief about me didn’t feel like a “belief”. It felt like <em>a basic
          truth of what I was</em>, the kind of truth that you just know - in
        the same way that you might look at an apple and <em>just know</em> you
        are having the experience of seeing an apple. But when I investigated
        the details of that experience, I realized that this wasn’t actually a
        fact about me. Rather it was just a belief that I had. </p>
      <p>In a similar way, there are many aspects of our subjective experience
        that feel like facts about reality, but upon doing insight practices and
        investigating them closer, we can come to see that they are not so.</p>
      <p>The philosopher Daniel Dennett has coined the term "<u><span><span><span><a
                  href="https://en.wikipedia.org/wiki/Heterophenomenology">heterophenomenology</a></span></span></span></u>"
        to refer to a particular approach to the study of consciousness. In this
        approach, we assume that people are correctly describing how things <em>seem</em>
        to them and treat this as something that needs to be explained. However,
        the actual mechanism of why things seem like that to them, may be
        different from what they assume.</p>
      <p>If I see an apple, it typically feels to me like I am seeing reality as
        it is. From a scientific point of view, this is mistaken: the sight of
        an apple is actually a complex interpretation my brain has created.
        Likewise, if I have the experience that I can never be happy, then this
        also feels like a raw fact while actually being an interpretation. In
        either case, if I manage to do practices which reveal my interpretation
        to be flawed, they will subjectively feel like I am investigating
        reality... while from a third-person perspective, we would rather say
        that I am investigating the way my mind builds up reality.</p>
      <p>It is valid to stick to just the first-person experience of
        investigating reality directly. Many of these practices are framed
        solely in those terms, because a stance of curiosity and having as few
        assumptions as possible is the best mindset for actually doing the
        practices. But if one says that meditation investigates the nature of
        reality, then it becomes hard to test the claim from a third-person
        perspective. A common criticism is that meditation certainly <em>changes</em>
        how people experience the world, but it might just as well be <em>loosening</em>
        their grasp on reality.</p>
      <p>On the other hand, if we provisionally assume that meditation works by
        revealing how the mind structures its model of reality, then we can
        check whether the kinds of insights that people report are compatible
        with what science tells us about the brain. If it turns out that
        meditators doing insight practices are coming up with experiences that
        match our understanding of actual brain mechanisms, then the practices
        might actually provide insight rather than delusion. In cases where no
        scientific evidence is yet available, it should at least be possible to
        construct a model that <em>could</em> be true and compatible with the
        third-person evidence.</p>
      <p>In <u><span><span><span><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip">previous
                  posts</a></span></span></span></u>, I have explored some
        scientifically-informed models of the brain, which I think are naturally
        linked to the kinds of discoveries made in insight meditation. This
        article will more explicitly connect concepts from the theory of
        meditation to those kinds of models.</p>
      <p>It is also worth noting that I think <em>both</em> claims about
        meditative insights are true: some things you can do with meditation <em>do</em>
        give you a better insight into reality, while some other things <em>do</em>
        just break your brain and reduce your contact with reality. (A fact
        responsible meditation teachers <u><span><span><span><a href="https://www.mctb.org/mctb2/table-of-contents/part-vi-my-spiritual-quest/61-crazy/">also
                  warn about</a></span></span></span></u>.) This makes it
        important to have third-person models of what could be a genuine insight
        and what is probably delusion, to help avoid the dangerous territory.</p>
      <h2 id="My_multiagent_model_of_mind">My multiagent model of mind</h2>
      <p>I have been calling my interpretation of those models a “<u><span><span><span><a
                  href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip">multiagent
                  model of mind</a></span></span></span></u>”. What follows is a
        highly abridged version of it; see the linked index of posts for much
        more extensive discussion, including the sources that I have been
        drawing on for my synthesis.</p>
      <p>One of the main ideas of the multiagent model is that the brain
        contains a number of different subsystems operating in parallel, each
        focusing on their own responsibilities. They share information on a
        subconscious level, but also through conscious thought. The content of
        consciousness <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain">roughly
                corresponds</a></span></span></u> to information which is being
        processed in a “global workspace” - a “brain web” of long-distance
        neurons, which link multiple areas of the brain together into a densely
        interconnected network. </p>
      <p>The global workspace can only hold a single piece of information at a
        time. At any given time, multiple different subsystems are trying to
        send information into the workspace, or otherwise modify its contents.
        Experiments show that a visual stimuli needs to be shown for about 50
        milliseconds for it to be consciously registered, suggesting that the
        contents of consciousness might be updated at least 20 times per second.
        Whatever information makes it into consciousness will then be broadcast
        widely throughout the brain, allowing many subsystems to synchronize
        their processing around it.</p>
      <p>The exact process by which this happens is not completely understood,
        but involves a combination of top-down mechanisms (e.g. attentional
        subsystems trying to strengthen particular signals and keep those in the
        workspace) as well as bottom-up ones (e.g. emotional content getting a
        priority). For example, if you are listening to someone talk in a noisy
        restaurant, both their words and the noise are bottom-up information
        within the workspace, while a top-down process tries to pick up on the
        words in particular. If a drunk person then suddenly collides with you,
        you are likely to become startled, which is a bottom-up signal strong
        enough to grab your attention (dominate the workspace), momentarily
        pushing away everything else.</p>
      <div style="text-align: center;"><span>
          <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Image3.png"
              class="draft-image " style="width:60%"></figure>
        </span></div>
      <p>There is also a constant learning process going on, where the brain
        learns which subsystems should be given access in which circumstances,
        while the subsystems themselves also undergo learning about what kind of
        information to send to consciousness.</p>
      <p>When I talk about “subsystems” sending content into consciousness, I
        mean this as a very generic term, which includes all of the following:</p>
      <ul>
        <li>Literal subsystems, e.g. information from the visual, auditory, and
          other sensory systems</li>
        <li>Subpatterns within larger subsystems, e.g. a particular neuronal
          pattern encoding a specific memory or habit</li>
        <li><u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain">Emotional
                  schemas</a></span></span></u> which trigger in particular
          situations and contain an interpretation of that situation and a
          response</li>
        <li>Working memory buffers <u><span><span><a class="PostLinkPreviewWithPost-link"
                  href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/HbXXd2givHBBLxr3d">associated
                  with type 2 (“System 2”)</a></span></span></u> reasoning,
          helping chain the outputs of several different subsystems together</li>
      </ul>
      <p>In some cases, I might talk about there being two separate subsystems,
        when one could argue that this would be better described as something
        like two separate pieces of data within a single subsystem. For example,
        I might talk about two different memories as two different subsystems,
        when one could reasonably argue that they are both contained within the
        same memory subsystem. Drawing these kinds of distinctions within the
        brain seems tricky, so rather than trying to figure out what term to use
        when, I will just talk about subsystems all the time.</p>
      <h2 id="Epistemic_status">Epistemic status</h2>
      <blockquote>Buddhist theories of the mind are based on textual traditions
        that purport to record the remembered word of the Buddha, on religious
        and philosophical interpretations of those texts, and on Buddhist
        practices of mental cultivation. The theories aren’t formulated as
        scientific hypotheses and they aren’t scientifically testable. Buddhist
        insights into the mind aren’t scientific discoveries. They haven’t
        resulted from an open-ended empirical inquiry free from the claims of
        tradition and the force of doctrinal and sectarian rhetoric. They’re
        stated in the language of Buddhist metaphysics, not in an independent
        conceptual framework to which Buddhist and non-Buddhist thinkers can
        agree. Buddhist meditative texts are saturated with religious imagery
        and language. Buddhist meditation isn’t controlled experimentation. It
        guides people to have certain kinds of experiences and to interpret them
        in ways that conform to and confirm Buddhist doctrine. The claims that
        people make from having these experiences aren’t subject to independent
        peer review; they’re subject to assessment within the agreed-upon and
        unquestioned framework of the Buddhist soteriological path. [...] </blockquote>
      <blockquote>I’m not saying that Buddhist meditative techniques haven’t
        been experientially tested in any sense. Meditation is a kind of skill,
        and it’s experientially testable in the way that skills are, namely,
        through repeated practice and expert evaluation. I have no doubt that
        Buddhist contemplatives down through the ages have tested meditation in
        this sense. I’m also not saying that meditation doesn’t produce
        discoveries in the sense of personal insights. (Psychoanalysis can also
        lead to insights.) Rather, my point is that the experiential tests
        aren’t experimental tests. They don’t test scientific hypotheses. They
        don’t provide a unique set of predictions for which there aren’t other
        explanations. The insights they produce aren’t scientific discoveries.
        [...]</blockquote>
      <blockquote>I’m also not trying to devalue meditation. On the contrary,
        I’m trying to make room for its value by showing how likening it to
        science distorts it. Meditation isn’t controlled experimentation.
        Attention and mindfulness aren’t instruments that reveal the mind
        without affecting it. Meditation provides insight into the mind (and
        body) in the way that body practices like dance, yoga, and martial arts
        provide insight into the body (and mind). Such mind-body
        practices—meditation included—have their own rigor and precision. They
        test and validate things experientially, but not by comparing the
        results obtained against controls.</blockquote>
      <blockquote>-- Evan Thompson, <em><span><span><span><a href="https://www.amazon.com/Why-I-Am-Not-Buddhist/dp/0300226551">Why
                  I Am Not A Buddhist</a></span></span></span></em></blockquote>
      <p>I think it is reasonable to believe that meditation can give us genuine
        insights into the way the mind functions. The meditative techniques and
        practices which I am drawing upon in this series have been developed
        within Buddhist traditions, and I make frequent references to the theory
        developed within those traditions.</p>
      <p>At the same time, while I am drawing upon theories developed within
        these traditions, I am treating those as a source of inspiration to be
        critically examined, rather than as sources of authority. </p>
      <p>For one, there are many different Buddhist theories and schools that
        disagree with each other, many of them claiming to teach <span><span><span><a
                href="https://vividness.live/2015/11/25/what-the-buddha-really-said/">what
                the Buddha <em>really </em>meant</a></span></span></span>. And
        as e.g. Evan Thompson’s book discusses, one cannot cleanly separate
        Buddhist meditative techniques from Buddhist religious teaching. People
        who meditate using those techniques - myself included - do so while
        being guided by an existing conceptual framework, framing their
        experiences in light of their framework. Practitioners who use different
        kinds of techniques and frameworks end up drawing different conclusions:
        e.g. some frameworks end up at the conclusion that no selves exist,
        while others end up believing that everything is self. (The extent to
        which this difference in framing actually leads to a different <em>experience</em>
        is unclear.) Many of these frameworks also draw upon supernatural
        elements, such as claims of rebirth and remembering past lives.</p>
      <p>Still, many meditation teachers also say things along the lines of “you
        should not take any of this on faith, just try it out and see for
        yourself”. Personally I started out skeptical of many claims, dismissing
        them as pre-scientific folk-psychological speculation, before gradually
        coming to believe in them - sometimes as a result of meditation which
        hadn’t even been aimed at investigating those claims in particular, but
        where I thought I was doing something completely different. And it seems
        to me that many of the meditative techniques actively require you to <em>suspend</em>
        your expectations in order to work properly, requiring you to look at
        what’s present rather than at the thing you expect to see.</p>
      <p>So, like many others, I simultaneously believe that i) meditative
        techniques point at genuine insights and also produce them in the minds
        of people who meditate and also that ii) we should not put excess faith
        in the claims of the existing meditation traditions. As many teachers
        encourage exactly this line of thought - as in the comment of taking
        nothing on faith - this feels like an appropriate spirit for approaching
        these matters.</p>
      <p>Rather than trying to be authentically Buddhist, this article is
        concerned with building a model of the neural and psychological
        mechanisms I think the three characteristics are pointing at, even if
        that model ends up sharply deviating from the original theories. I
        heavily draw on my own experiences and the experiences and theories of
        other people whose reports I have reason to trust. I proceed from the
        assumption that regardless of whether the original frameworks are true
        or false, they do systematically produce similar effects and insights in
        the minds of the people following them, and that is an <u><span><span><a
                class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/MPj7t2w3nk4s9EYYh/incorrect-hypotheses-point-to-correct-observations">observation
                which needs to be explained</a></span></span></u>. </p>
      <p>In fact, I am happy to mix and match examples, exercises,
        interpretations and results drawn from all of the contemplative
        traditions that I happen to have any familiarity with, with current-day
        Western psychology and psychotherapy thrown in for good measure. They
        may have different approaches, but to the extent that they share
        commonalities, those commonalities tell us something about what human
        minds might have in common. And to the extent that they differ, one
        tradition might be pointing out aspects about the human mind that the
        others have neglected and vice versa, as in the fable of the blind men
        and the elephant.</p>
      <h1 class="MuiTypography-root MuiTypography-display3 PostsPageTitle-root">A
        non-mystical explanation of "no-self"</h1>
      <div>
        <p><br>
        </p>
        <div>
          <h2 id="On_the_three_characteristics">On the three characteristics</h2>
          <p>So, just what are <u><span><span><span><a href="https://en.wikipedia.org/wiki/Three_marks_of_existence">the
                      three characteristics of existence</a></span></span></span></u>?</p>
          <p>My take is that they are <em>a rough way of clustering the kinds
              of insights that you may get from insight meditation</em>: in one
            way or another, most insights about the structure of your mind can
            be said to be about no-self, impermanence, unsatisfactoriness, or
            some combination of them. As upcoming posts should hopefully make
            obvious, this is not a very clear-cut distinction: the three are
            deeply intertwined with each other, and you can’t fully explain one
            without explaining the others. I am starting with a discussion of
            no-self, then moving to unsatisfactoriness, then coming back to
            no-self, moving between the different characteristics in a way that
            seems most clear.</p>
          <p>I think that what’s called “enlightenment” refers to the gradual
            accumulation of these kinds of insights, combined with practices
            aimed at exploiting an understanding of them. There are many
            different insights and ways of exploring them, as well as many
            general <u><span><span><span><a href="https://approachingaro.org/yanas">approaches
                      for making use of them</a></span></span></span></u>.
            Different traditions also seem to have different enlightenments [<u><span><span><span><a
                      href="https://www.inquiringmind.com/article/2701_w_kornfield-enlightenments/">1</a></span></span></span></u>,
            <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/yxvp9LErWao5kJ3bC/multiplicity-of-enlightenment-states-and-contemplative">2</a></span></span></u>].
            Thus, rather than providing any definitive explanation of “<em>this</em>
            is enlightenment”, I attempt to focus on exploring how various
            cognitive mechanisms behind different enlightenments work. My intent
            is to cover enough of different things to give a taste of what's out
            there and what kinds of outcomes might be possible, while
            acknowledging that there's also a lot that I have no clue of yet.</p>
          <p>So this is not trying to be anything like “a definitive and
            complete explanation of the three characteristics”; I don’t think
            anyone could write such a thing, as nobody can have explored all the
            aspects of all the three. Rather, this is more of a sketch of those
            aspects of the three characteristics which I think I have some
            understanding of. </p>
          <p>In particular, this explanation strongly emphasizes no-self and
            unsatisfactoriness, which I feel I have a better understanding of.
            Impermanence, which some approaches consider the very core
            characteristic, ends up relatively neglected. Apologies to any
            impermanence fans - maybe some day I’ll come back to write more
            about it.</p>
          <p>But let’s get started with talking about no-self.</p>
          <h2 id="No_self">No-self</h2>
          <p>No-self is a confusing term, since it can easily be interpreted as
            the claim that, well, there is no self. But at least on one
            interpretation of Buddhism, the claim is much more subtle. Here’s an
            excerpt from the article <u><span><span><span><a href="https://www.accesstoinsight.org/lib/authors/thanissaro/notself2.html">No-self
                      or Not-self?</a></span></span></span></u>, by the Buddhist
            monk <u><span><span><span><a href="https://en.wikipedia.org/wiki/%E1%B9%ACh%C4%81nissaro_Bhikkhu">Thanissaro
                      Bhikkhu</a></span></span></span></u>:</p>
          <blockquote>In fact, the one place where the Buddha was asked
            point-blank whether or not there was a self, he refused to answer.
            When later asked why, he said that to hold either that there is a
            self or that there is no self is to fall into extreme forms of wrong
            view that make the path of Buddhist practice impossible. Thus the
            question should be put aside. [...]</blockquote>
          <blockquote>So, instead of answering "no" to the question of whether
            or not there is a self — interconnected or separate, eternal or not
            — the Buddha felt that the question was misguided to begin with. </blockquote>
          <p>Now, there are many interpretations of Buddha’s teaching, and <u><span><span><span><a
                      href="https://vividness.live/2015/11/25/what-the-buddha-really-said/">what
                      the Buddha even really said</a></span></span></span></u>
            in the first place; other people will offer a different kind of an
            account. But let’s suppose that this particular interpretation <em>is</em>
            correct. What might it mean?</p>
          <p>Well, clearly people <em>feel</em> that something like a “self
            exists”. But <u><span><span><a class="PostLinkPreviewWithPost-link"
                    href="https://www.lesswrong.com/posts/Mc6QcrsbH5NRXbCRX/dissolving-the-question">rather
                    than arguing</a></span></span></u> about whether or not a
            self exists, one should investigate the mechanisms by which the
            experience of having a self is constructed. Once those cognitive
            algorithms are understood, one knows what creates a <em>feeling</em>
            of having a self - and then there is nothing more to explain.</p>
          <p>Of course, in Buddha’s day, they did not have cognitive science and
            a theory of neural networks, so he was unable to express his
            position in those terms. They did, however, have well-developed
            meditative techniques. And those techniques could be used to
            investigate how the experience of having a self was developed.</p>
          <p>Now, one might reasonably ask, if the question of “does the self
            exist” is misleading, then why is this often phrased in the form of
            the claim that the self does <em>not</em> exist?</p>
          <h3 id="_The_self_does_not_exist_in_the_way_you_think_">“The self does
            not exist in the way you think”</h3>
          <p>In my daily experience, it generally feels like there <u><span><span><span><a
                      href="https://plato.stanford.edu/entries/identity-personal/">exists
                      a distinct “me”</a></span></span></span></u>. There is <em>someone</em>,
            an “I” who sees what I see, hears what I hear, feels what I feel. It
            feels like I can generally make choices, consider information, act
            according to my best judgment. It feels that there’s a meaningful
            sense in which the same me existed yesterday, and will continue to
            exist tomorrow. If you were to make a copy of me that was
            atom-to-atom identical, I <u><span><span><span><a href="https://en.wikipedia.org/wiki/Teletransportation_paradox">might
                      intuitively feel</a></span></span></span></u> that there
            would exist a distinct difference between the original me and the
            copy. We might be exactly identical and act exactly the same, but
            there would still be a different <em>experiencer</em>.</p>
          <p>But I also know about the scientific “multi-agent” models of mind,
            described briefly in <u><span><span><a class="PostLinkPreviewWithPost-link"
                    href="https://www.lesswrong.com/posts/Mf2MCkYgSZSJRz5nM/a-non-mystical-explanation-of-insight-meditation-and-the">my
                    last post</a></span></span></u> and more extensively in <u><span><span><span><a
                      href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip">earlier
                      ones</a></span></span></span></u>, where different
            subsystems within the brain are responsible for my actions. In those
            models, there is no privileged subsystem in charge of making
            decisions. Different subsystems take charge at different times,
            based on a preconscious selection process which is not under the
            control of any particular subsystem. There is also no particular
            subsystem which could be singled out as <em>the</em> one
            experiencing things. Rather, anything which makes it to
            consciousness is broadcast into many different subsystems, each of
            which can do different things with that information.</p>
          <p>So experientially, I feel like I have a self which works in a
            particular way. Science suggests that my mind actually works in a
            different way: e.g. decisions are made by a distributed collection
            of semi-independent subsystems, rather than by a distinct "deciding
            self". So some might claim that the self <em>as I intuitively
              experience it</em> does not exist, as the intuitive conception
            does not match reality. </p>
          <p>For example, <em><u><span><span><span><a href="https://wisdomexperience.org/academy/wp-content/uploads/sites/4/2016/07/Manual-of-Insight-for-Course.pdf">The
                        Manual of Insight</a></span></span></span></u></em> is a
            treatise on meditation by the Theravada Buddhist monk Mahasi
            Sayadaw, who had a significant impact on spreading insight
            meditation in the West. The book quotes the Theravada scripture of <u><span><span><span><a
                      href="https://en.wikipedia.org/wiki/Pa%E1%B9%ADisambhid%C4%81magga">Paṭisambhidāmagga</a></span></span></span></u>
            as saying, in its elaboration of no-self, that:</p>
          <blockquote>There is no self that is able to control, to own, to feel,
            to give orders, to behave according to one’s will, no self that is
            everlasting, or that is the agent of going, seeing, and so on. [...]</blockquote>
          <blockquote>[As a result of meditation practice, one comes to see the
            mind as] empty of self (suññato). Here “self” (atta) means an entity
            that is the owner of the body, permanently residing in the body, the
            agent of going, seeing, and so on, the agent who feels pleasant and
            unpleasant feelings, able to give any orders, and able to exercise
            mastery. Such an entity, which is [a product of one’s] speculation,
            belief, or obsession, may be called being, soul, ego, or self.</blockquote>
          <p>Likewise, Daniel Ingram, meditation teacher and author of the
            widely-read book <em>Mastering the Core Teachings of the Buddha,</em>
            <u><span><span><span><a href="https://mctb.org/mctb2/table-of-contents/part-i-the-fundamentals/5-the-three-characteristics/">writes
                      that</a></span></span></span></u> (emphasis mine):</p>
          <blockquote>The original Pali term, anatta, means literally
            “not-self”. This same term is also rendered by other authors in
            other ways, some of which can be extremely problematic, such as
            egolessness, a terribly problematic term, since ego as understood in
            the Western psychological sense is not the referent of the
            conception of “self” targeted in Buddhism. Another problematic
            rendering of this term is “emptiness”. Emptiness, for all its
            mysterious-sounding connotations, means that <strong>reality is
              empty of, devoid of, or lacking a permanent, separate,
              independent, acausal, autonomous self</strong>. It doesn’t mean
            that reality is not there, but that reality is not there in the way
            it may appear to us to be. [...]</blockquote>
          <blockquote>It’s not that the constellation labeled “me”, or “you”, a
            grouping of physical and mental components, does not exist and
            function in some ordinary sense. <strong>It’s that none of those
              components exist independently or acausally, which is how
              ignorance conceives of them.</strong> Ultimate unfindability of
            the components of reality in no way precludes their conventional
            existence!</blockquote>
          <p>Intellectually many people do not think that their self has an
            acausal existence, independent of the laws of physics. But the kind
            of understanding one can get from meditation is different. As I will
            discuss, the ways that specific subsystems react to various
            situations is linked to their model of the self. Normally, even if
            you intellectually understand that you do not have an acausally
            acting self, your mind cannot directly <em>see</em> the actual
            causality. Many of the subconscious models driving your behavior
            will only update if they are forced to directly witness evidence
            contradicting their old assumptions. (For a previous discussion of
            this in the context of psychotherapy and emotional beliefs, see <u><span><span><a
                    class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain">my
                    review of <em>Unlocking the Emotional Brain</em></a></span></span></u>.)</p>
          <h3 id="Early_insights_into_no_self">Early insights into no-self</h3>
          <p>Recall again the model that the content of consciousness roughly
            corresponds to a “<u><span><span><a class="PostLinkPreviewWithPost-link"
                    href="https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain">global
                    workspace</a></span></span></u>” which contains information
            submitted by different subsystems. In normal circumstances, there
            are some objects in the stream of experience (global workspace)
            which the overall system treats as being more “me” than the rest.
            For example, many people experience themselves as inhabiting a space
            somewhere behind their eyes, looking at the world from that
            location. </p>
          <p>Suppose that I now do some kind of practice where I examine this
            experience in more detail. Here is a simple one:</p>
          <ol>
            <li>Look at an object in front of you. Spend a moment simply
              examining its features.</li>
            <li>Become aware of the sensation of being someone who is looking at
              this object. While letting your attention rest on the object, try
              to notice what this sensation of being someone who is looking at
              the object feels like. Does it have a location, shape, or feel?</li>
          </ol>
          <p>You may wish to take a moment to do this right now, before reading
            about my results.</p>
          <p>.</p>
          <p>.</p>
          <p>.</p>
          <p>.</p>
          <p>.</p>
          <p>.</p>
          <p>When I do this kind of exercise, a result that I may get is that
            there is the sight of the object, and then a pattern of tension
            behind my eyes. <em>Something</em> about the pattern of tension
            feels like “me” - when I feel that “I am looking at a plant in front
            of me”, this could be broken down to “there is a tension in my
            consciousness, it feels like the tension is what’s looking at the
            plant, and that tension feels like me”.</p>
          <p>Your result may be different from this. You may find yourself
            identifying with another sensation, or you might not be able to hone
            down on any particular sensation on the first try… but if you are
            like most people, you probably still have <em>some</em> kind of a
            feeling of looking out at the world.</p>
          <p>My guess is that this sensation is a tag coming from some subsystem
            whose task is to keep track of one’s spatial location relative to
            their surroundings. We know that there are multiple such systems in
            the brain, and that these systems getting out of sync - one system
            indicating a particular location and another indicating a differing
            location - <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/MPj7t2w3nk4s9EYYh/incorrect-hypotheses-point-to-correct-observations">can
                    create the feeling of an out-of-body experience</a></span></span></u>.
            In computer terms, sensory data comes in, and then some subsystem
            parses that sensory data and indicates where one’s “I” is located,
            passing this tag for other subsystems to use. Going by the previous
            example of me feeling a tension around my eyes that feels like me
            looking at the plant, we might think that something like the
            following is happening:</p>
          <ul>
            <li>Subsystem 1 sends the sight of a plant into the global workspace</li>
            <li>Subsystem 2 sends the feeling of tension around the eyes into
              the global workspace</li>
            <li>Subsystem 3 tags the tension as my current location, and binds
              all of these percepts together as an experience of “I am seeing
              the plant”, which is also sent to the global workspace</li>
          </ul>
          <p>An interesting thing is that the subsystems in the brain seem to
            take the tag as an ontological fact. Suppose that someone hands you
            a map of your surroundings, and has helpfully marked your current
            location with a red tag saying “YOU ARE HERE”. </p>
          <div style="text-align: center;"><span>
              <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/YouAreHere.png"
                  class="draft-image center" style="width:47%"></figure>
            </span></div>
          <p>But suppose that you now get a little confused. Rather than taking
            the spot with red ink as <em>indicating</em> your location in your
            physical world, you take the red spot on the map to <em>be</em>
            your physical location. That is, you think that you <em>are</em>
            the “YOU ARE HERE” tag, looking at the rest of the map <em>from</em>
            the red ink itself. </p>
          <p>But of course, the fact that you are seeing the above picture,
            means that you cannot be looking <em>from</em> the red ink in the
            picture. The map includes the red ink, meaning that the person who
            is looking at it is actually <em>outside</em> the map.</p>
          <p>Likewise, people tend to have a sensation of looking at the world
            from behind their eyes; but they are actually aware <em>of</em> the
            sensation, as opposed to being aware <em>from</em> it. It is a
            computational representation of a location, rather than being the
            location itself. Still, once this representation is fed into other
            subsystems in the brain, those subsystems will treat the tagged
            location as the one that they are “looking at the sense data from”,
            as if they had been fed a physical map of their surroundings with
            their current location marked.</p>
          <p>But a particular tag in the sense data is not actually where they
            are looking at it from; for one, the visual cortex is located in the
            back of the head, rather than right behind the eyes. Furthermore,
            any visual information is in principle just a piece of data that has
            been fed into a program running in the brain. If we think of
            cognitive programs as analogous to computer programs, then a
            computer program that is fed a piece of data isn't really "looking
            at" the data "from" any spatial direction.</p>
          <p>In vipassana-style meditation, you train your attention to dissect
            components of your experience into smaller pieces. (Vipassana is
            commonly translated as insight meditation, but here I treat it as a
            particular subcategory of insight meditation.) In third-person
            terms, this probably trains up pattern-detectors which can monitor
            the content of the global workspace in extreme detail. Eventually,
            there’s sufficient clarity about the sense of location for low-level
            schemas to pick up on the inherent contradiction involved in looking
            <em>at</em> something which the system is supposedly looking <em>out
              from</em>. </p>
          <p>The opposite strategy is commonly associated with what are
            so-called <u><span><span><span><a href="https://en.wikipedia.org/wiki/Nondualism">nondual
                      techniques</a></span></span></span></u>. Instead of
            training an analytical, attention-controlled part of the mind to
            examine the sense of self, the nondual route is to nudge the mind
            into a state where those analytical parts of the brain become less
            active. As those parts also produce the sense of ‘the observer’ in
            the first place, attenuating their activity can offer a glimpse into
            a state of consciousness where that sensation is lacking. Some
            versions of this approach seem to be tapping into some of the same
            machinery which causes people to experience a state of flow, as flow
            states also seem to involve a downregulation in both analytical
            thought and the sense of self.</p>
          <p>Frequently, the sense of self being diminished in this way is a
            sufficiently interesting experience that the analytical subsystems
            kick back online to make sense of it - but over time, one can train
            oneself to experience more such glimpses, until there is a broader
            shift.</p>
          <p>It is not clear to me to what extent these routes lead to exactly
            the same result. It seems to me that both eventually end up at a
            state where the sensations tagging one’s physical location still
            continue to be produced, and can be used as an aid for spatial
            reasoning, but the system no longer intrinsically identifies with
            them. Rather, the sensations are seen as being constructed by a
            machinery which is independent of the actual stream of sensory
            input. </p>
          <p>But there seem to be some differences in how you reach that place.
            For the sake of analogy, let's pretend that the machinery is a
            hologram projector, painting a realistic image of a person in the
            middle of a room. The vipassana path would correspond to looking
            very closely at all the details of the hologram, until you noticed
            discrepancies in how it was created. That would give you a detailed
            insight into how exactly the projector used light to draw the image,
            but would be rather slow. In contrast, the nondual route involves
            just turning the projector off for a moment - making it very obvious
            that the hologram was in fact a hologram, but telling you much less
            of how it was built. </p>
          <p>Another difference is the no-self versus all-self interpretation.
            Some schools say that this kind of practice leads you to realizing
            that there is no self; other schools, generally more associated with
            Hinduism than Buddhism, say that they lead you to realizing that all
            is self. (Western philosophy has the corresponding concepts of <u><span><span><span><a
                      href="https://en.wikipedia.org/wiki/Open_individualism">closed,
                      open and empty individualism</a></span></span></span></u>.)</p>
          <p>Some of the end results from both paths are described in a similar
            way, however. For example, a common metaphor about the result of
            some varieties of practice is that of “being the sky rather than the
            clouds”. Below is one formulation of it. The outcome seems to be
            that rather than identifying with the sensations of the supposed
            observer, one’s identity shifts to <em>the entire field of
              consciousness itself </em>(in line with the thing about a program
            reading a file not having any location that would be defined in
            terms of the file):</p>
          <blockquote>One way of describing the experience of glimpsing in
            effortless mindfulness practice is to use the metaphor of a cloud.
            You may have felt as if you have been living in a cloud; maybe it
            feels like a storm cloud a lot of the time. See if you can feel the
            boundary and fogginess of this cloud that you call “me.” You may
            have been trying to feel better by cleaning up the cloud of your
            mind by replacing negative thoughts with positive thoughts and
            developing good attitudes. You may have tried to calm your body and
            mind to make your brain as clear as possible. Within your cloud are
            storms, old traumas, emotional challenges, and relationships of all
            types. Each time you change these things and clean up one area of
            the cloud, it seems that another foggy issue or thunderous problem
            arises.</blockquote>
          <blockquote>Effortless mindfulness does not begin with dissolving the
            cloud, calming it, or trying to transform its contents. The
            glimpsing method of effortless mindfulness begins with awake
            awareness stepping out of the cloud, shifting, dropping, or opening
            to discover that you are also the open sky of awake awareness! When
            you shift out of this cloud of the emotional or small mind and
            discover this spaciousness of still, quiet, alert awareness, it’s a
            great relief. You can realize that you are the sky, and the cloudy
            emotions and thoughts are everchanging weather.</blockquote>
          <blockquote>[...] As we reach the fullness of effortless mindfulness,
            we will discover open-hearted awareness and ways to naturally
            embrace and welcome all emotions and parts of ourselves. [...] After
            all, all weather comes and goes, and no storm ever hurt the sky.</blockquote>
          <blockquote>(Loch Kelly, <u><span><span><span><a href="https://smile.amazon.com/Way-Effortless-Mindfulness-Revolutionary-Awakened-ebook/dp/B07FDR6M2T/">The
                      Way of Effortless Mindfulness</a></span></span></span></u>)</blockquote>
          <p>Or this more concrete description, quoted in a paper on
            meditation-induced changes to the sense of self (<u><span><span><span><a
                      href="https://www.ingentaconnect.com/contentone/imp/jcs/2019/00000026/f0020007/art00008?crawler=true&amp;mimetype=application%2Fpdf">Lindahl
                      &amp; Britton 2019</a></span></span></span></u>):</p>
          <blockquote>So, [the retreat] was in the spring and I was doing some
            raking leaves, and just as I was raking, this really profound
            feeling of ‘this is all me’ came to me. And so the ‘this is all me’
            — what that means is that my identity is literally everything that I
            could see through my eyes. So, the rake that I was holding in my
            hands was me. The ground that I was raking was me. The feet that I
            could see down at the bottom of my body, that was me. The steps up
            to the residence, that was me. The sky was me. The trees were me.
            And so, everything was just ‘me’. And that there wasn’t really
            anything else. It was all just ‘me’. […] Those experiences that I
            related about what I would call kenshō experiences, there was no
            viewer in those — it was just what was there, and there was no
            viewer observing it.</blockquote>
          <p>Here is how I would rephrase these reports in third-person terms.
            Normally, there is a flow of information within the global
            workspace: mental objects representing sensory information,
            thoughts, and some objects encoding a sense of there being someone
            who watches the senses. These kinds of experiences are a part of a
            process where the system reorients its assumptions to recognize that
            there is no homunculus sitting behind the eyes and watching
            everything. </p>
          <p>From an external point of view, we can say that <em>your conscious
              mind - or “you” - consists of everything that is in the global
              workspace, and no particular piece of mental content is more or
              less “you” than the others are</em>. If you see a rake in your
            hands, then there is a process within your brain generating that
            visual experience. The experience exists as a part of your mind.
            Likewise, the experience of there being a <em>someone</em> who is <em>having</em>
            that experience, is generated by a process within your brain, and
            exists as a part of your mind. <em>Everything that you ever
              experience is mental content generated by your brain,</em> as
            opposed to you having <u><span><span><span><a href="https://en.wikipedia.org/wiki/Na%C3%AFve_realism_%28psychology%29">direct
                      access to reality</a></span></span></span></u>. </p>
          <p>Now, in Loch Kelly’s quote above, there is the suggestion that
            changing one’s identification to the entire field of consciousness
            will also change how one relates to negative experiences. Exactly
            why this would happen is an important question, and I will come back
            to it later. For now, let’s look a bit more at why getting such an
            experience can be so difficult.</p>
          <h3 id="The_self_as_a_tool_for_planning">The self as a tool for
            planning</h3>
          <p>A thing that might happen, once the above has been explained to
            you, is that you put a lot of effort into <em>intellectually</em>
            figuring out the contradiction between experiencing something that
            you also identify with, and then figuring out what must be going on
            instead. This kind of theorizing can be useful for purposes of
            writing articles such as this one. But you cannot use theorizing
            alone to put your brain into a no-self state by convincing your
            brain of the contradiction. Meditation teachers may explicitly warn
            you that it is impossible for your thinking mind to comprehend
            no-self states in such a way that would cause you to actually <em>experience</em>
            them.</p>
          <p>I suspect that a part of this is because the subsystems in the
            brain used for this kind of theorizing take the sense of self as
            input. As a result, them being active tends to put the mind in a
            state where it identifies more strongly with the sensations of a
            self.</p>
          <p>Going back to the map analogy, consider the route-finding algorithm
            included in Google Maps: you give it a starting location, an end
            location, some parameters of what kind of a route you prefer, and it
            then finds you the best route that meets those criteria.</p>
          <p>I suggested that the sense of the observer is like a point in a
            map, saying “YOU ARE HERE”, and that one of the goals of practice
            was coming to see that the point that’s marked on the map cannot
            actually be “your” real location. That is, some part of your mind
            stops treating the red ink on the map as being identical to where
            you are. But a route-finding algorithm does not have the option of
            treating the starting point of a route as anything else than as the
            starting point of a route. Its <em>entire purpose</em> is to assume
            that the “YOU ARE HERE” really does correspond to your real
            location, and to then plot a route from there. If it didn’t, it
            wouldn’t be a route-finding algorithm anymore.</p>
          <p>What I am calling “intellectual” parts of your brain, seem to be
            similar to route-finding algorithms. Their purpose is to figure out
            a path from where you are now, to some desired target state. </p>
          <p>The literature on expertise suggests that people figure out novel
            tasks by running mental simulations of how to get from a current
            state to a target state, and then trying to carry out a sequence
            that they have successfully simulated (<u><span><span><span><a href="https://smile.amazon.com/Sources-Power-People-Decisions-Press-dp-0262534290/dp/0262534290/">Klein
                      1999</a></span></span></span></u>). For example, you might
            be faced with a truck sitting on the ground. Using a jack and
            concrete blocks, you want to get it up on the air on a column of
            blocks.</p>
          <div style="text-align: center;"><span>
              <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Truck.png"
                  class="draft-image center" style="width:54%"></figure>
            </span></div>
          <p>You mentally go through different options, until you figure out a
            sequence of steps that gets you to the end result. When you find
            something that seems promising enough, you give it a shot.</p>
          <div style="text-align: center;"><span>
              <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Truck2.png"
                  class="draft-image center" style="width:66%"></figure>
            </span></div>
          <p>Now, in the example of a truck, your reasoning can happen purely in
            terms of what is going to happen to the truck; the same process
            would work exactly the same regardless of whether you or someone
            else was doing it. But what happens if you set the goal of “<em>I </em>want
            to get to a state where <em>I </em>experience no sense of self?”</p>
          <p>This again fires up the parts of your brain that carry out mental
            simulations… but just as in the truck example, where they needed to
            track what was happening to the truck in each step of the sequence,
            they now need to track whether or not <em>you</em> are experiencing
            a sense of self in any given step. This makes it impossible for them
            to find a state where you wouldn’t experience a sense of self, as
            the very act of trying to plan how to get you there requires
            instantiating a sense of self that represents you in the simulation!
          </p>
          <p>This can make for some frustrating experiences, in that if you once
            experience a state with a drastically weakened sense of self, it may
            feel pleasant and you then want to get back to it. But trying to
            figure out how to get back into it, is exactly the kind of a process
            that may <em>prevent</em> you from getting back. This is part of
            the reason why some traditions and teachers say things like “in
            order to get enlightened, you must stop striving for enlightenment”,
            as well as claiming that thinking in terms of outcomes is contrary
            to the spirit of the practice. </p>
          <p>What the planning system would actually need to do to achieve its
            goal, is to simply turn itself off, so that it stops projecting a
            sense of self into the global workspace. But it cannot accurately
            represent this target state, as it parses it as “a state where <em>I
            </em>experience no sense of self”. Its representation of the target
            still includes a sense of someone who either is or is not
            experiencing a sense of self. </p>
          <p>To use the map analogy, this is something like asking Google Maps
            to route a path to a state where the Google Maps program has been
            turned off. There is simply no way for it to do that, because the
            notion of being on or off is not explicitly represented anywhere in
            the program. The pathfinding routine of Google Maps only reasons in
            terms of where “you” are in the maps that are loaded into it.</p>
          <p>What the route-finding algorithm in Google Maps <em>can</em> do,
            is something like take a map, find the location on it that sounds
            the closest to “turn yourself off”, and plot a route to that. Of
            course, this will not actually turn it off, but it is something that
            the algorithm can at least <em>do</em>. So upon being given the
            task of turning itself off, it will plot a route to that location,
            correctly notice that this is not actually fulfilling the task that
            it was given, and trash around trying to find a better target
            location. This corresponds to a meditator thinking something like
            “oh, how do I get into a no-self state again, oh wait, if I <em>try</em>
            to get into a no-self state I can’t do it, so I have to stop trying
            to get to it… so now I am going to stop trying to get to it… wait,
            that is trying again, gahhhhhh.”</p>
          <br>
          <div style="text-align: center;"><span>
              <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/TurnOff.png"
                  class="draft-image center" style="width:100%"></figure>
            </span></div>
          <span> </span></div>
        <p><em>Google Maps trying to figure out where "turn off" is. This
            location isn’t quite it, but maybe it would at least be getting
            close?</em></p>
        <p>This runs into the contradiction between the way that we often think
          about our minds, and the way that our minds actually work. We often
          have the feeling that at least <em>some</em> of the content in our
          consciousness is something that we can actively choose. Most people
          don’t expect to be able to choose their emotions, but at least the act
          of <em>intentionally trying to do something</em> feels like it should
          be under conscious control - isn’t that what intentionally acting <em>means</em>?</p>
        <p>But under a multi-agent framework, “trying to do something” simply
          means that a subsystem is active and pursuing a particular goal.
          Neither the subsystem itself, nor any other subsystem, has direct
          access to a command which would turn that subsystem off: the choice of
          which subsystem to activate or keep running, happens by means of a <u><span><span><a
                  class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/7zQPYQB5EeaqLrhBh/subagents-neural-turing-machines-thought-selection-and">preconscious
                  selection process</a></span></span></u>. That means that,
          despite it possibly going against one’s naive intuition, it is
          perfectly possible to consciously intend to do something while also
          having no conscious control over the fact that you are intending to do
          so.</p>
        <p>As I noted before, there are several approaches to dealing with this
          problem. For example, <u><span><span><span><a href="https://en.wikipedia.org/wiki/Flow_%28psychology%29">flow
                    states</a></span></span></span></u> typically involve
          activities that are similar to the truck task, in that they do not
          require a sense of self. At the same time, the task is challenging
          enough that it requires one’s full attention: in other words, a single
          planning subsystem uses up the full bandwidth of consciousness, being
          the only one that projects content to the global workspace. If there
          was any spare capacity, other planning systems could project
          self-related thoughts at the same time (e.g. thinking about what to do
          after the current task is done), thus instantiating a sense of self.
          Thus, getting the mind into something like a flow state is one way to
          reduce the sense of self.</p>
        <p>On the other hand, some situations just trigger the self-related
          planning machinery very strongly. In vipassana/mindfulness-style
          approaches, one frequently ends up creating a sense of being an
          observer who is detached from their thoughts and emotions. For
          example, a simple set of “labeling” instructions is just:</p>
        <ol>
          <li>Notice something in your consciousness.</li>
          <li>Give it a label, such as <u><span><span><span><a href="https://www.shinzen.org/wp-content/uploads/2016/08/SeeHearFeelIntroduction_ver1.8.pdf">“seeing”,
                      “feeling”, or “hearing”</a></span></span></span></u>.</li>
          <li>Go back to 1.</li>
        </ol>
        <p>In these instructions, the planning machinery is given a goal that it
          <em>is</em> capable of carrying out. Following these instructions does
          instantiate a sense of self - the planning system needs to monitor the
          question of “am <em>I</em> still labeling my experience”. However,
          this task constructs an experience where the “I” is merely <em>observing</em>
          other mental content, and that mental content is happening on its own.</p>
        <p>This can be particularly useful in situations which are experienced
          as important or potentially threatening, as those kinds of situations
          tend to make goal-oriented systems kick in very strongly to help
          resolve the situation. For people with trauma and ongoing anxiety,
          this might include even situations with no immediate external
          concerns; such people may almost constantly be in a state of
          uncertainty, activating planning systems with the goal of making those
          unpleasant feelings go away. If one practices dispassionately
          observing the contents of their mind, even when the content is
          unpleasant, one can in effect train up a new subsystem that competes
          with the other subsystems in projecting content to the global
          workspace. (However, it needs to be noted that training the mind to
          closely examine unpleasant feelings may also <u><span><span><span><a
                    href="https://books.google.fi/books?id=medHDwAAQBAJ&amp;lpg=PT8&amp;ots=YoBhBQTtwX&amp;dq=%22Part%20of%20me%20wished%20I%20hadn%E2%80%99t%20seen%20the%20e-mail.%22&amp;pg=PT8#v=onepage&amp;q&amp;f=false">make
                    trauma responses <em>worse</em></a></span></span></span></u>
          by bringing more attention to them and interfering with the subsystems
          that were previously regulating the responses.)</p>
        <p>In this, one continues the process of identifying with a self, but
          the thing that is being identified with shifts to a sense of someone
          who is just observing everything happening in the mind - which can
          bring relief from various unpleasant emotions. Once one gets to this
          kind of a state, the subsystem trained to do this can continue to
          further investigate the contents of the mind in fine detail… either
          looking at other characteristics like impermanence or
          unsatisfactoriness, or turning its focus <em>on itself</em>, to
          deepen the no-self realization by seeing that the observer self that
          it is projecting is <em>also</em> something that can be
          dis-identified with.</p>
        <p>The meditation teacher <u><span><span><span><a href="https://deconstructingyourself.com/">Michael
                    Taft</a></span></span></span></u> describes this kind of a
          turn in his article on <u><span><span><span><a href="https://www.reddit.com/r/Meditation/comments/2nposb/escaping_the_observer_trap_deconstructing_yourself/">Escaping
                    the Observer Trap</a></span></span></span></u>:</p>
        <blockquote>Many traditions—especially mindfulness meditation—encourage
          you to observe your sensory experience in a neutral manner. Observe
          your breathing, observe emotions, observe thoughts, and so on, without
          reacting to them. This observer technique works really well because it
          gives you something like an outside perspective on your own
          experience. You can watch your own mind, your reactions, your
          emotions, your behavior almost from the perspective of another person,
          and that is tremendously useful feedback to have. It leads to
          equanimity, and the tremendous personal growth that mindfulness
          advocates are always talking about. [...]</blockquote>
        <blockquote>Taking this observer stance is so useful, in fact, that many
          teachers stop there and do not talk about the next important step in
          spiritual development. But there is a hidden problem with the observer
          technique, which becomes obvious once you think about it. Who is the
          observer? Who is this person who is behind the binoculars, watching
          your experience from the outside? This neutral observer you’ve created
          over time is actually just another—albeit smaller and less
          neurotic—version of the ego. It’s the sense of being a person who is
          doing the meditating. You could also call it a meditator ego or an
          observer ego. Creating this neutral observer is very useful, but the
          goal of meditation is not to create a new meditator ego, it’s to see
          through the illusion of the ego entirely.</blockquote>
        <blockquote>It is quite common for even very dedicated mindfulness
          students in observation-based traditions to get stuck in observer mode
          forever. I have seen it over and over in my experience. Being the
          observer, a neutral meditator ego, is not such a bad place to be;
          certainly it is much preferable to the unconscious, robotic mode of
          life lived without any self-reflection. However, it impedes all deeper
          progress toward real awakening. So the only way forward is to let go
          of the observer ego; to release the sense of being a person who is
          doing a meditation. [...]</blockquote>
        <blockquote>To release yourself from the observer trap, begin by
          realizing that the observer, however comfortable or habitual, is still
          just another version of the ego. You’ve spent endless hours watching
          your breath and your emotions and your thoughts. Now it’s time to
          watch the watcher instead. You have to observer the observer. You do
          this, in typical mindfulness style, by carefully deconstructing the
          components of the observer itself.</blockquote>
        <blockquote>The observer ego is constructed out of the same components
          as the everyday ego, but on a smaller scale. The everyday mind has
          thoughts about all sorts of stuff, the observer has thoughts about how
          the mediation is going, or how long until this sit is over. The
          everyday ego has emotions about all sorts of stuff, but observer has
          emotions about how this sit is going, or even blissful feelings of
          love and joy. The everyday ego has all sorts of body sensations, but
          the observer has a very special set of body sensations: the sensations
          of where he/she imagines awareness is located. [...] So to overcome
          the observer problem and get unstuck in your practice, closely observe
          the sensations (i.e. the thoughts and feelings) associated with the
          observer ego.<br>
          <br>
          <h1 class="MuiTypography-root MuiTypography-display3 PostsPageTitle-root">
            <br>
            Craving, suffering, and predictive processing</h1>
          <div>
            <p><em>This is the third post of the "a non-mystical explanation of
                insight meditation and the three characteristics of existence</em>"
              <em>series.</em> <em>I originally intended this post to more
                closely connect no-self and unsatisfactoriness, but then decided
                on focusing on unsatisfactoriness in this post and relating it
                to no-self in the next one.</em></p>
            <p><br>
            </p>
            <div>
              <h2 id="Unsatisfactoriness">Unsatisfactoriness</h2>
              <p>In the previous post, I discussed some of the ways that the
                mind seems to construct a notion of a self. In this post, I will
                talk about a specific form of motivation, which Buddhism
                commonly refers to as <em><u><span><span><span><a href="https://en.wikipedia.org/wiki/Ta%E1%B9%87h%C4%81">craving</a></span></span></span></u></em>
                (<em>taṇhā</em> in the original Pali). Some discussions
                distinguish between craving (in the sense of wanting positive
                things) and aversion (wanting to avoid negative things); this
                article uses the definition where both desire and aversion are
                considered subtypes of craving.</p>
              <p>My model is that craving is generated by a particular set of
                motivational subsystems within the brain. Craving is not the <em>only</em>
                form of motivation that a person has, but it normally tends to
                be the loudest and most dominant. As a form of motivation,
                craving has some advantages:</p>
              <ul>
                <li>People tend to experience a strong craving to pursue
                  positive states and avoid negative states. If they had less
                  craving, they might not do this with an equal zeal.</li>
                <ul>
                  <li>To some extent, craving looks to me like a mechanism that
                    shifts behaviors from <u><span><span><a class="PostLinkPreviewWithPost-link"
                            href="https://www.lesswrong.com/posts/TSNZRtzefZYaLBjR7/the-embarrassing-problem-of-premature-exploitation">exploration
                            to exploitation</a></span></span></u>.</li>
                  <li>In an earlier post, <u><span><span><a class="PostLinkPreviewWithPost-link"
                            href="https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model">Building
                            up to an Internal Family Systems model</a></span></span></u>,
                    I suggested that the human mind might incorporate mechanisms
                    that acted as priority overrides to avoid repeating
                    particular catastrophic events. Craving feels like a major
                    component of how this is implemented in the mind.</li>
                </ul>
                <li>Craving tends to be automatic and visceral. A strong craving
                  to eat when hungry may cause a person to get food when they
                  need it, even if they did not intellectually understand the
                  need to eat.</li>
              </ul>
              <p>At the same time, craving also has a number of disadvantages:</p>
              <ul>
                <li>Craving superficially looks like it cares about <em>outcomes</em>.
                  However, it actually cares about <em>positive or negative
                    feelings </em>(<u><span><span><span><a href="https://en.wikipedia.org/wiki/Valence_%28psychology%29">valence</a></span></span></span></u>).
                  This can lead to behaviors that are akin to <u><span><span><span><a
                            href="https://wiki.lesswrong.com/wiki/Wireheading">wireheading</a></span></span></span></u>
                  in that they suppress the unpleasant feeling while doing
                  nothing about the problem. If thinking about death makes you
                  feel unpleasant and going to the doctor reminds you of your
                  mortality, you may avoid doctors - even if this actually <em>increases</em>
                  your risk of dying.</li>
                <li>Craving narrows your perception, making you only pay
                  attention to things which seem immediately relevant for your
                  craving. <span><span><span><a href="https://s3-us-west-2.amazonaws.com/dharmanetworks-meditatetucker/13.+Links+of+Dependent+Origination+1.mp3">For
                          example</a></span></span></span>, if you have a
                  craving for sex and go to a party with the goal of finding
                  someone to sleep with, you may see everyone only in terms of
                  “will sleep with me” or “will not sleep with me”. This may not
                  be the best possible way of classifying everyone you meet.</li>
                <li>Strong craving may cause <u><span><span><a class="PostLinkPreviewWithPost-link"
                          href="https://www.lesswrong.com/posts/TSNZRtzefZYaLBjR7/the-embarrassing-problem-of-premature-exploitation#Premature_Exploitation">premature
                          exploitation</a></span></span></u>. If you have a
                  strong craving to achieve a particular goal, you may not want
                  to do anything that looks like moving away from it, even if
                  that would actually help you achieve it better. For example,
                  if you intensely crave a feeling of accomplishment, you may
                  get stuck playing video games that make you feel like you are
                  accomplishing something, even if there was something else that
                  you could do that was more fulfilling in the long term.</li>
                <li>Multiple conflicting cravings may cause you to thrash around
                  in an unsuccessful attempt to fulfill all of them. If you
                  crave to get your toothache fixed, but also a craving to avoid
                  dentists, you may put off the dentist visit even as you
                  continue to suffer from your toothache.</li>
                <li>Craving seems to act in part by creating self-fulfilling
                  prophecies; making you strongly believe that you are going to
                  achieve something, so as to cause you to do it. The stronger
                  the craving, the stronger the false beliefs injected into your
                  consciousness. This may warp your reasoning in all kinds of
                  ways: updating to believe an unpleasant fact may subjectively
                  feel like you are allowing that fact to become true by
                  believing in it, incentivizing you to come up with ways to
                  avoid believing in it.</li>
                <li>Finally, although craving is often motivated by a desire to
                  avoid unsatisfactory experiences, it is actually the very
                  thing that causes dissatisfaction in the first place. Craving
                  assumes that negative feelings are intrinsically unpleasant,
                  when in reality they only become unpleasant when craving
                  resists them.</li>
              </ul>
              <p>Given all of these disadvantages, it may be a good idea to try
                to shift one’s motivation to be more driven by subsystems that
                are not motivated by craving. It seems to me that everything
                that can be accomplished via craving, can <em>in principle</em>
                be accomplished by non-craving-based motivation as well.</p>
              <p>Fortunately, there are several ways of achieving this. For one,
                a craving for some outcome X tends to implicitly involve at
                least two assumptions: </p>
              <ol>
                <li>achieving X is necessary for being happy or avoiding
                  suffering</li>
                <li>one cannot achieve X <em>except</em> by having a craving
                  for it</li>
              </ol>
              <p>Both of these assumptions are false, but subsystems associated
                with craving have a built-in bias to selectively sample evidence
                which supports these assumptions, making them frequently feel
                compelling. Still, it is possible to give the brain evidence
                which lets it know that these assumptions are wrong: that it is
                possible to achieve X without having craving for it, <em>and</em>
                that one can feel good regardless of achieving X.</p>
              <h3 id="Predictive_processing_and_binocular_rivalry">Predictive
                processing and binocular rivalry</h3>
              <p>I find that a promising way of looking at unsatisfactoriness
                and craving and their impact on decision-making comes from the
                predictive processing (PP) model about the brain. My claim is
                not that craving would work <em>exactly</em> like this, but
                something roughly like this seems like a promising analogy.</p>
              <p>Good introductions to PP include <u><span><span><span><a href="https://slatestarcodex.com/2017/09/05/book-review-surfing-uncertainty/">this
                          book review</a></span></span></span></u> as well as
                the <u><span><span><span><a href="https://www.amazon.com/Surfing-Uncertainty-Prediction-Action-Embodied/dp/0190217014">actual
                          book in question</a></span></span></span></u>... but
                for the purposes of this discussion, you really only need to
                know two things:</p>
              <ul>
                <li>According to PP, the brain is constantly attempting to find
                  a model of the world (or hypothesis) that would both explain
                  and predict the incoming sensory data. For example, if I upset
                  you, my brain might predict that you are going to yell at me
                  next. If the next thing that I hear is you yelling at me, then
                  the prediction and the data match, and my brain considers its
                  hypothesis validated. If you do <em>not</em> yell at me, then
                  the predicted and experienced sense data conflict, sending off
                  an error signal to force a revision to the model.</li>
                <li>Besides changing the model, another way in which the brain
                  can react to reality not matching the prediction is by
                  changing reality. For example, my brain might predict that I
                  am going to type a particular sentence, and then fulfill that
                  prediction by moving my fingers so as to write that sentence.
                  PP goes so far as to claim that this is the mechanism behind <em>all</em>
                  of our actions: a part of your brain predicts that you are
                  going to do something, and then you do it so as to fulfill the
                  prediction.</li>
              </ul>
              <p>Next I am going to say a few words about a phenomenon called <u><span><span><span><a
                          href="https://en.wikipedia.org/wiki/Binocular_rivalry">binocular
                          rivalry</a></span></span></span></u> and how it is
                interpreted within the PP paradigm. I promise that this is going
                to be relevant for the topic of craving and suffering in a bit,
                so please stay with me.</p>
              <p>Binocular rivalry, first discovered in 1593 and extensively
                studied since then, is what happens when your left eye is shown
                one picture (e.g. an image of Isaac Newton), and your right eye
                is shown another (e.g. an image of a house) in the right. People
                report that their experience keeps alternating between seeing
                Isaac Newton and seeing a house. They might also see a brief
                mashup of the two, but such Newton-houses are short-lived and
                quickly fall apart before settling to a stable image of either
                Newton or a house.</p>
              <div style="text-align: center;"><span>
                  <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/binocular.png"
                      class="draft-image center" style="width:52%"></figure>
                </span></div>
              <span> </span></div>
            <p><em>Image credit: Schwartz et al. (2012), <span><span><span><a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rstb.2011.0254">Multistability
                        in perception: binding sensory modalities, an overview</a></span></span></span>.
                Philosophical Transactions of the Royal Society B, 367, 896-905.</em></p>
            <p>Predictive processing explains what’s happening as follows. The
              brain is trying to form a stable hypothesis of what exactly the
              image data that the eyes are sending represents: is it seeing
              Newton, or is it seeing a house? Sometimes the brain briefly
              considers the hybrid hypothesis of a Newton-house mashup, but this
              is quickly rejected: faces and houses do not exist as occupying
              the same place at the same scale at the same time, so this idea is
              clearly nonsensical. (At least, nonsensical outside highly
              unnatural and contrived experimental setups that psychologists
              subject people to.)</p>
            <p>Your conscious experience alternating between the two images
              reflects the brain switching between the hypotheses of “this is
              Isaac Newton” and “this is a house”; the currently-winning
              hypothesis is simply what you experience reality as.</p>
            <p>Suppose that the brain ends up settling on the hypothesis of “I
              am seeing Isaac Newton”; this matches the input from the
              Newton-seeing eye. As a result, there is no error signal that
              would arise from a mismatch between the hypothesis and the
              Newton-seeing eye’s input. For a moment, the brain is satisfied
              that it has found a workable answer. </p>
            <p>However, if one really was seeing Isaac Newton, then the <em>other</em>
              eye should not keep sending an image of a house. The hypothesis
              and the house-seeing eye’s input <em>do</em> have a mismatch,
              kicking off a strong error signal which lowers the brain’s
              confidence in the hypothesis of “I am seeing Isaac Newton”. </p>
            <div style="text-align: center;"><span>
                <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/MatchNewton.png"
                    class="draft-image center" style="width:70%"></figure>
              </span></div>
            <span> </span></div>
          <p>The brain goes looking for a hypothesis which would better satisfy
            the strong error signal… and then finds that the hypothesis of “I am
            seeing a house” serves to entirely quiet the error signal from the
            house-seeing eye. Success?</p>
          <p>But even as the brain settles on the hypothesis of “I am seeing a
            house”, this then contradicts the input coming from the <em>Newton-seeing
              eye. </em></p>
          <div style="text-align: center;"><span>
              <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/MatchHouse.png"
                  class="draft-image center" style="width:74%"></figure>
            </span></div>
          <span> </span></blockquote>
      </div>
      <p>The brain is again momentarily satisfied, before the incoming error
        signal from the hypothesis/Newton-eye mismatch drives down the
        probability of the “I am seeing a house” hypothesis, causing the brain
        to eventually go back to the “I am seeing Isaac Newton” hypothesis...
        and then back to seeing a house, and then to seeing a Newton, and...</p>
      <div style="text-align: center;"><span>
          <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/alteration.png"
              class="draft-image center" style="width:57%"></figure>
        </span></div>
      <span> </span></div>
    <p>One way of phrasing this is that there are two subsystems, each of which
      are transmitting a particular set of constraints (about seeing Newton and
      a house). The brain is then trying and failing to find a hypothesis which
      would fulfill both sets of constraints, while <em>also</em> respecting
      everything else that it knows about the world. </p>
    <p>As I will explain next, my feeling is that something similar is going on
      with unsatisfactoriness. Craving creates constraints about what the world
      should be like, and the brain tries to find an action which would fulfill
      all of the constraints, while also taking into account everything else
      that it knows about the world. Suffering/unsatisfactoriness emerges when
      all of the constraints are impossible to fulfill, either because achieving
      them takes time, or because the brain is unable to find any scenario that
      could fulfill all of them even in theory.</p>
    <h3 id="Predictive_processing_and_psychological_suffering">Predictive
      processing and psychological suffering</h3>
    <p>There are two broad categories of suffering: mental and physical
      discomfort. Let’s start with the case of psychological suffering, as it
      seems most directly analogous to what we just covered.</p>
    <p>Let’s suppose that I have broken an important promise that I have made to
      a friend. I feel guilty about this, and want to confess what I have done.
      We might say that I have a craving to avoid the feeling of guilt, and the
      associated craving subsystem sends a prediction to my consciousness: I
      will stop feeling guilty. </p>
    <p>In the previous discussion, an inference mechanism in the brain was
      looking for a hypothesis that would satisfy the constraints imposed by the
      sensory data. In this case, the same thing is happening, but</p>
    <ul>
      <li>the hypothesis that it is looking for is a possible action that I
        could take, that would lead to the constraint being fulfilled</li>
      <li>the sensory data is not actually coming from the senses, but is
        internally generated by the craving and represents the outcome that the
        craving subsystem would like to see realized</li>
    </ul>
    <p>My brain searches for a possible world that would fulfill the provided
      constraints, and comes up with the idea of just admitting the truth of
      what I have done. It predicts that if I were to do this, I would stop
      feeling guilty over not admitting my broken promise. This satisfies the
      constraint of not feeling guilty.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/ScrewedUp.png"
            class="draft-image center" style="width:61%"></figure>
      </span></div>
    <span> </span>
    <p>However, as my brain further predicts what it expects to happen as a
      consequence, it notes that my friend will probably get quite angry. This
      triggers another kind of craving: to not experience the feeling of getting
      yelled at. This generates its own goal/prediction: that nobody will be
      angry with me. This acts as a further constraint for the plan that the
      brain needs to find. </p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/ScrewedUpAngryy.png"
            class="draft-image center" style="width:74%"></figure>
      </span></div>
    <span> </span>
    <p>As the constraint of “nobody will be angry at me” seems incompatible with
      the plan of “I will admit the truth”, this generates an error signal,
      driving down the probability of this plan. My brain abandons this plan,
      and then considers the alternative plan of “I will just stay quiet and not
      say anything”. This matches the constraint of “nobody will be angry at me”
      quite well, driving down the error signal from that particular
      plan/constraint mismatch… but then, if I don’t say anything, I will
      continue feeling guilty.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/ScrewedUpGuiltyy.png"
            class="draft-image center" style="width:72%"></figure>
      </span></div>
    <span> </span>
    <p>The mismatch with the constraint of “I will stop feeling guilty” drives
      up the error signal, causing the “I will just stay quiet” plan to be
      abandoned. At worst, my mind may find it impossible to find any plan which
      would fulfill both constraints, keeping me in an endless loop of
      alternating between two unviable scenarios.</p>
    <p>There are some interesting aspects about the phenomenology of such a
      situation, which feel like they fit the PP model quite well. In
      particular, it may feel like <em>if I just focus on a particular craving
        enough, thinking about my desired outcome hard enough will make it true</em>.</p>
    <p>Recall that under the PP framework, goals happen because a part of the
      brain <em>assumes</em> that they will happen, after which it changes
      reality to <em>make</em> that belief true. So focusing really hard on a
      craving for X makes it feel like X will become true, <em>because the
        craving is literally rewriting an aspect of my subjective reality to
        make me think that X will become true</em>. </p>
    <p>When I focus hard on the craving, I am temporarily guiding my attention
      away from the parts of my mind which are pointing out the obstacles in the
      way of X coming true. That is, those parts have less of a chance to
      incorporate <em>their</em> constraints into the plan that my brain is
      trying to develop. This momentarily reduces the motion away from this
      plan, making it seem more plausible that the desired outcome will in fact
      become real.</p>
    <p>Conversely, letting go of this craving, may feel like it is <em>literally
        making the undesired outcome more real</em>, rather than like I am
      coming more to terms with reality. This is most obvious in cases where one
      has a craving for an outcome that is impossible for certain, such as in
      the case of grieving about a friend’s death. Even after it is certain that
      someone is dead, there may still be persistent thoughts of <em>if only I
        had done X, </em>with an implicit additional flavor of <em>if I just
        want to have done X really hard, things will change, and I can’t stop
        focusing on this possibility because my friend </em>needs<em> to be
        alive.</em></p>
    <p>In this form, craving may lead to all kinds of <u><span><span><span><a href="https://www.lesswrong.com/s/GSqFqc646rsRd2oyz">rationalization</a></span></span></span></u>
      and biased reasoning: a part of your mind is literally making you believe
      that X is true, because it wants you to find a strategy where X is true.
      This hallucinated belief may constrain all of your plans and models about
      the world in the same sense as <em>getting direct sensory evidence about
        X being true</em> would constrain your brain’s models. For example, if I
      have a <em>very</em> strong urge to believe that someone is interested in
      me, then this may cause me to interpret <em>any</em> of his words and
      expressions in a way compatible with this belief, regardless of how
      implausible and <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/s/GSqFqc646rsRd2oyz/p/wyyfFfaRar2jEdeQK">far-spread</a></span></span></u>
      of a distortion this requires.</p>
    <h3 id="The_case_of_physical_pain">The case of physical pain</h3>
    <p>Similar principles apply to the case of physical pain.</p>
    <p>We should first note that pain does not necessarily need to be aversive:
      for example, people may enjoy the pain of exercise, hot spices or sexual
      masochism. Morphine may also have an effect where people report that they
      still experience the pain but no longer mind it. </p>
    <p>And, relevant for our topic, people practicing meditation find that by
      shifting their attention <em>towards</em> pain, it can become <em>less</em>
      aversive. The meditation teacher Shinzen Young writes that</p>
    <blockquote>... pain is one thing, and resistance to the pain is something
      else, and when the two come together you have an experience of suffering,
      that is to say, 'suffering equals pain multiplied by resistance.' You'll
      be able to see that's true not only for physical pain, but also for
      emotional pain and it’s true not only for little pains but also for big
      pains. It's true for every kind of pain no matter how big, how small, or
      what causes it. Whenever there is resistance there is suffering. As soon
      as you can see that, you gain an insight into the nature of "pain as a
      problem" and as soon as you gain that insight, you'll begin to have some
      freedom. You come to realize that as long as we are alive we can't avoid
      pain. It's built into our nervous system. But we can certainly learn to
      experience pain without it being a problem. (<u><span><span><span><a href="https://sci-hub.tw/10.1080/08873267.1994.9976936">Young,
                1994</a></span></span></span></u>)</blockquote>
    <p>What does it mean to say that <em>resisting</em> pain creates suffering?</p>
    <p>In the discussion about binocular rivalry, we might have said that when
      the mind settled on a hypothesis of seeing Isaac Newton, this hypothesis
      was <em>resisted</em> by the sensory data coming from the house-seeing
      eye. The mind would have settled on the hypothesis of “I am seeing Isaac
      Newton”, if not for that resistance. Likewise, in the preceding
      discussion, the decision to admit the truth was resisted by the desire to
      not get yelled at.</p>
    <p>Suppose that you have a sore muscle, which hurts whenever you put weight
      on it. Like sensory data coming from your eyes, this constrains the
      possible interpretations of what you might be experiencing: your brain
      might settle on the hypothesis of “I am feeling pain”.</p>
    <p>But the experience of this hypothesis then triggers a <em>resistance</em>
      to that pain: a craving subsystem wired to detect pain and resist it by
      projecting a form of internally-generated sense data, effectively claiming
      that you are <em>not </em>in pain. There are now again two incompatible
      streams of data that need to be reconciled, one saying that you are in
      pain, and another which says that you are not. </p>
    <p>In the case of binocular rivalry, both of the streams were generated by
      sensory information. In the discussion about psychological suffering, both
      of the streams were generated by craving. In this case, craving generates
      one of the streams and sensory information generates the other.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Paain.png"
            class="draft-image center" style="width:64%"></figure>
      </span></div>
    <span> </span>
    <p><em>On the left, a persistent pain signal is strong enough to dominate
        consciousness. On the right, a craving for not being in pain attempts to
        constrain consciousness so that it doesn’t include the pain.</em></p>
    <p>Now if you stop putting weight on the sore muscle, the pain goes away,
      fulfilling the prediction of “I am not in pain”. As soon as your brain
      figures this out, your motor cortex can incorporate the craving-generated
      constraint of “I will not be in pain” into its planning. It generates
      different plans of how to move your body, and whenever it predicts that
      one of them would violate the constraint of “I will not be in pain”, it
      will revise its plan. The end result is that you end up moving in ways
      that avoid putting weight on your sore muscle. If you miscalculate, the
      resulting pain will cause a rapid error signal that causes you to adjust
      your movement again.</p>
    <p>What if the pain is more persistent, and bothers you no matter how much
      you try to avoid moving? Or if the circumstances force you to put weight
      on the sore muscle?</p>
    <p>In that case, the brain will continue looking for a possible hypothesis
      that would fulfill the constraint of “I am not in pain”. For example,
      maybe you have previously taken painkillers that have helped with your
      pain. In that case, your mind may seize upon the hypothesis that “by
      taking painkillers, my pain will cease”.</p>
    <p>As your mind predicts the likely consequences of taking painkillers, it
      notices that in this simulation, the constraint of “I am not in pain” gets
      fulfilled, driving down the error signal between the hypothesis and the “I
      am not in pain” constraint. However, if the brain could suppress the
      craving-for-pain-relief merely by <em>imagining</em> a scenario where the
      pain was gone, then it would never need to take any actions: it could just
      hallucinate pleasant states. Helping keep it anchored into reality is the
      fact that simply imagining the painkillers has not done anything to the
      pain signal itself: the imagined state does not match your actual sense
      data. There is still an error signal generated between the mismatch of the
      imagined “I have taken painkillers and am free of pain” scenario, and the
      fact that the pain is not gone yet.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/PainSimulation.png"
            class="draft-image center" style="width:64%"></figure>
      </span></div>
    <span> </span>
    <p><em>Your brain imagines a possible experience: taking painkillers and
        being free of pain. This imagined scenario fulfills the constraint of “I
        have no pain”. However, it does not fulfill the constraint of actually
        matching your sense data: you have <strong>not</strong> yet taken
        painkillers and <strong>are</strong> still in pain.</em></p>
    <p>Fortunately, if painkillers are actually available, your mind is not
      locked into a state where the two constraints of “I’m in pain” and “I’m
      not in pain” remain equally impossible to achieve. It can take actions -
      such as making you walk towards the medicine cabinet - that get you closer
      towards being able to fulfill both of these constraints.</p>
    <p>There are studies suggesting that physical pain and psychological pain
      share similar neural mechanisms [<em>citation</em>]. And in meditation,
      one may notice that psychological discomfort and suffering involves
      avoiding unpleasant sensations in the same way as physical pain does; the
      same mechanism has been recruited for more abstract planning. </p>
    <p>When the brain predicts that a particular experience would produce an
      unpleasant sensation, craving resists that prediction and tries to find
      another way. Similarly, if the brain predicts that something will <em>not</em>
      produce a pleasant sensation, craving may also resist <em>that</em>
      aspect of reality.</p>
    <p>Now, this process as described has a structural equivalence to binocular
      rivalry, but as far as I know, binocular rivalry does not involve any
      particular discomfort. Suffering obviously does. </p>
    <p>Being in pain is generally bad: it is usually better to try to avoid
      ending up in painful states, as well as try to get out of painful states
      once you are in them. This is also true for other states, such as hunger,
      that do not necessarily feel painful, but still have a negative emotional
      tone. Suppose that whenever craving generates a self-fulfilling prediction
      which resists your direct sensory experience, this generates a signal we
      might call “unsatisfactoriness”. </p>
    <p>The stronger the conflict between the experience and the craving, the
      stronger the unsatisfactoriness - so that a mild pain that is easy to
      ignore only causes a little unsatisfactoriness, and an excruciating pain
      that generates a strong resistance causes immense suffering. The brain is
      then wired to use this unsatisfactoriness as a training signal, attempting
      to avoid situations that have previously included high levels of it, and
      to keep looking for ways out if it currently has a lot of it.</p>
    <p>It is also worth noting what it means for you to be paralyzed by two
      strong, mutually opposing cravings. Consider again the situation where I
      am torn between admitting the truth to my friend, and staying quiet. We
      might think that this is a situation where the overall system is uncertain
      of the correct course of action: some subsystems are trying to force the
      action of confronting the situation, others are trying to force the action
      of avoiding it. Both courses of action are predicted to lead to some kind
      of loss.</p>
    <p>In general, it is a bad thing if a system ends up in a situation where it
      has to choose between two different kinds of losses, and has high internal
      uncertainty of the right action. A system should avoid such dilemmas,
      either by avoiding the situations themselves or by finding a way to
      reconcile the conflicting priorities. </p>
    <h3 id="Craving_based_and_non_craving_based_motivation">Craving-based and
      non-craving-based motivation</h3>
    <p>What I have written so far might be taken to suggest that craving is a
      requirement for all action and planning. However, the Buddhist claim is
      that craving is actually just one of at least two different motivational
      systems in the brain. Given that neuroscience suggests the existence of <u><span><span><a
              class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/fa5o2tg9EfJE77jEQ/the-human-s-hidden-utility-function-maybe">at
              least <em>three</em> different motivational systems</a></span></span></u>,
      this should not seem particularly implausible.</p>
    <p>Let’s take another look at the types of processes related to binocular
      rivalry versus craving.</p>
    <p>Craving acts by actively introducing false beliefs into one’s reasoning.
      If craving could just do this completely uninhibited, rewriting <em>all</em>
      experience to match one’s desires, nobody would ever do anything: they
      would just sit still, enjoying a craving-driven hallucination of a world
      where everything was perfect.</p>
    <p>In contrast, in the case of binocular rivalry, no system is feeding the
      reasoning process any false beliefs: all the constraints emerge directly
      from the sense data and previous life-experience. To the extent that the
      system can be said to have a preference over either the “I am seeing a
      house” or the “I am seeing Isaac Newton” hypothesis, <u><span><span><span><a
                href="https://wiki.lesswrong.com/wiki/Litany_of_Tarski">it is
                just</a></span></span></span></u> “if seeing a house is the most
      likely hypothesis, then I prefer to see a house; if seeing Newton is the
      most likely hypothesis, then I prefer to see Newton”. The computation does
      not have an intrinsic attachment to any particular outcome, nor will it
      hallucinate a particular experience if it has no good reason to.</p>
    <p>Likewise, it seems like there are modes of doing and being which are
      similar in the respect that one is focused on process rather than outcome:
      taking whatever actions are best-suited for the situation at hand,
      regardless of what their outcome might be. In these situations, little
      unsatisfactoriness seems to be present.</p>
    <p>In an earlier post, I <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model">discussed</a></span></span></u>
      a <u><span><span><span><a href="https://owainevans.github.io/blog/hirl_blog.html">proposal</a></span></span></span></u>
      where an autonomously acting robot has two decision-making systems. The
      first system just figures out whatever actions would maximize its rewards
      and tries to take those actions. The second “Blocker” system tries to
      predict whether or not a human overseer would approve of any given action,
      and prevents the first system from doing anything that would be
      disapproved of. We then have two evaluation systems: “what would bring the
      maximum reward” (running on a lower priority) and “would a human overseer
      approve of a proposed action” (taking precedence in case of a
      disagreement).</p>
    <p>It seems to me that there is something similar going on with craving.
      There are processes which are neutrally just trying to figure out the best
      action; and when those processes hit upon particularly good or bad
      outcomes, craving is formed in an attempt to force the system into
      repeating or avoiding those outcomes in the future.</p>
    <p>Suppose that you are in a situation where the best possible course of
      action only has a 10% chance of getting you through alive. If you are in a
      non-craving-driven state, you may focus on getting at least that 10%
      chance together, since that’s the best that you can do.</p>
    <p>In contrast, the kind of behavior that is typical for craving is
      realizing that you have a significant chance of dying, deciding that this
      thought is completely unacceptable, and refusing to go on before you have
      an approach where the thought of death isn’t so stark.</p>
    <p>Both systems have their upsides and downsides. If it is true that a 10%
      chance of survival really is the best that you can do, then you should
      clearly just focus on getting the probability even that high. The craving
      which causes trouble by thrashing around is only going to make things
      worse. On the other hand, maybe this estimate is flawed and you could
      achieve a higher probability of survival by doing something else. In that
      case, the craving absolutely refusing to go on until you have figured out
      something better might be the right action.</p>
    <p>There is also another major difference, in that craving does not <em>really</em>
      care about outcomes. Rather, it cares about avoiding positive or negative
      feelings. In the case of avoiding death, craving-oriented systems are
      primarily reacting to the <em>thought</em> of death… which may make them
      reject even plans which would <em>reduce</em> the risk of death, if those
      plans involved needing to think about death too much.</p>
    <p>This becomes particularly obvious in the case of things like going to the
      dentist in order to have an operation you know will be unpleasant. You may
      find yourself highly averse to going, as you crave the comfort of not
      needing to suffer from the unpleasantness. At the same time, you <em>also</em>
      know that the operation will benefit you in the long term: any
      unpleasantness will just be a passing state of mind, rather than permanent
      damage. But avoiding unpleasantness - including the very thought of
      experiencing something unpleasant - is just what craving is about.</p>
    <p>In contrast, if you are in a state of equanimity with little craving, you
      still recognize the thoughts of going to the dentist as having negative
      valence, but this negative valence does not bother you, because you do not
      have a craving to avoid it. You can choose whatever option seems best,
      regardless of what kind of content this ends up producing in your
      consciousness.</p>
    <p>Of course, choosing correctly requires you to actually <em>know</em>
      what is best. Expert meditators have been known to sometimes ignore
      extreme physical pain that should have caused them to seek medical aid.
      And they probably <em>would</em> have sought help, if not for their
      ability to drop their resistance to pain and experience it with extreme
      equanimity.</p>
    <p>Negative-valence states tend to correlate with states which are bad for
      the achievement of our goals. That is the reason why we are wired to avoid
      them. But the correlation is only partial, so if you focus too much on
      avoiding unpleasantness, you are falling victim to <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/EbFABnst8LsidYs5Y/goodhart-taxonomy">Goodhart’s
              Law</a></span></span></u>: optimizing a measure so much that you
      sacrifice the goals that the measure was supposed to track. Equanimity
      gives you the ability to ignore your consciously experienced suffering, so
      you don't need to pay additional mental costs for taking actions which
      further your goals. This can be useful, if you are strategic about
      actually achieving your goals. </p>
    <p>But while Goodharting on a measure is a failure mode, so is ignoring the
      measure entirely. Unpleasantness <em>does</em> still correlate with
      things that make it harder to realize your values, and the need to avoid
      displeasure normally operates as an automatic feedback mechanism. It is
      possible to have high equanimity and weaken this mechanism, <u><span><span><a
              class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/PBRWb2Em5SNeWYwwB/humans-are-not-automatically-strategic">without
              being smart about it</a></span></span></u> and doing nothing to
      develop alternative mechanisms. In that case you are just trading
      Goodhart’s Law for the opposite failure mode.</p>
    <h3 id="Some_other_disadvantages_of_craving">Some other disadvantages of
      craving</h3>
    <p>In the beginning of this post, I mentioned a few other disadvantages that
      craving has, which I have not yet mentioned explicitly. Let’s take a quick
      look at those.</p>
    <p><em>Craving narrows your perception, making you only pay attention to
        things that seem immediately relevant for your craving. </em></p>
    <p>In predictive processing, <u><span><span><a class="CommentLinkPreviewWithComment-link"
              href="https://www.lesswrong.com/posts/WFopenhCXyHX3ukw3/how-uniform-is-the-neocortex?commentId=MuYPzSszsZkdzXrMJ">attention
              is conceptualized</a></span></span></u> as giving increased
      weighting to those features of the sensory data that seem most useful for
      making successful predictions about the task at hand. If you have strong
      craving to achieve a particular outcome, your mind will focus on those
      aspects of the sensory data that seem useful for realizing your craving. </p>
    <p><em>Strong craving may cause <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/TSNZRtzefZYaLBjR7/the-embarrassing-problem-of-premature-exploitation#Premature_Exploitation">premature
                exploitation</a></span></span></u>. If you have a strong craving
        to achieve a particular goal, you may not want to do anything that looks
        like moving away from it, even if that would actually help you achieve
        it better. </em></p>
    <p>Suppose that you have a strong craving to experience a feeling of
      accomplishment: this means that the craving is strongly projecting a
      constraint of “I will feel accomplished” into your planning, causing an
      error signal if you consider any plan which does not fulfill the
      constraint. If you are thinking about a multistep plan which will take
      time before you feel accomplished, it will start out by you <em>not</em>
      feeling accomplished. This contradicts the constraint of “I will feel
      accomplished”, causing that plan to be rejected in favor of ones that
      bring you even <em>some</em> accomplishment right away.</p>
    <h3 id="Craving_and_suffering">Craving and suffering</h3>
    <p>We might summarize the unsatisfactoriness-related parts of the above as
      follows:</p>
    <ul>
      <li>Craving tries to get us into pleasant states of consciousness.</li>
      <li>But pleasant states of consciousness are those <em>without</em>
        craving.</li>
      <li>Thus, there are subsystems which are trying to get us into pleasant
        states of consciousness by creating constant craving, which is the exact
        <em>opposite</em> of a pleasant state.</li>
    </ul>
    <p>We can somewhat rephrase this as:</p>
    <ul>
      <li>The default state of human psychology involves a degree of almost
        constant dissatisfaction with one’s state of consciousness.</li>
      <li>This dissatisfaction is created by the craving.</li>
      <li>The dissatisfaction can be ended by eliminating craving.</li>
    </ul>
    <p>… which, if correct, might be interpreted to roughly equal the first
      three of Buddhism’s <u><span><span><span><a href="https://en.wikipedia.org/wiki/Four_Noble_Truths">Four
                Noble Truths</a></span></span></span></u>: the fourth is
      “Buddhism’s Noble Eightfold Path is a way to end craving”.</p>
    <p>A more rationalist framing might be that the craving is essentially
      acting in a way that looks similar to <u><span><span><span><a href="https://wiki.lesswrong.com/wiki/Wireheading">wireheading</a></span></span></span></u>:
      pursuing pleasure and happiness even if that sacrifices your ability to
      impact the world. Reducing the influence of the craving makes your
      motivations less driven by wireheading-like impulses, and more able to see
      the world clearly even if it is painful. Thus, reducing craving may be
      valuable even if one does not care about suffering less.</p>
    <p>This gives rise to the question - how exactly <em>does</em> one reduce
      craving? And what does all of this have to do with the self, again?</p>
    <p>We’ll get back to those questions in the next post.</p>
    <h1 class="MuiTypography-root MuiTypography-display3 PostsPageTitle-root"> <br>
      From self to craving</h1>
    <div>
      <p>Buddhists talk a lot about the self, and also about suffering. They
        claim that if you come to investigate what the self is really made of,
        then this will lead to a reduction in suffering. Why would that be?</p>
      <p>This post seeks to answer that question. First, let’s recap a few
        things that we have been talking about before.</p>
      <p><br>
      </p>
      <div>
        <h2 id="The_connection_between_self_and_craving">The connection between
          self and craving</h2>
        <p>In “<u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/W59Nb72sYJhMJKGB8/a-non-mystical-explanation-of-no-self-three-characteristics">a
                  non-mystical explanation of ‘no-self’</a></span></span></u>”,
          I talked about the way in which there are two kinds of goals. First,
          we can manipulate something that does not require a representation of
          ourselves. For example, we can figure out how to get a truck on a
          column of blocks.</p>
        <div style="text-align: center;"><span>
            <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Truck.png"
                class="draft-image center" style="width:67%"></figure>
          </span></div>
        <span> </span></div>
      <p>In that case, we can figure out a sequence of actions that takes the
        truck from its initial state to its target state. We don’t necessarily
        need to think about <em>ourselves</em> as we are figuring this out -
        the actual sequence could just as well be carried out by someone else.</p>
      <div style="text-align: center;"><span>
          <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Truck2.png"
              class="draft-image center" style="width:72%"></figure>
        </span></div>
      <span> </span></div>
    <p>I mentioned that these kinds of tasks seem to allow flow states, in which
      the sense of self becomes temporarily suspended as unnecessary, and which
      are typically experienced as highly enjoyable and free from discomfort.</p>
    <p>Alternatively, we can think of a goal which intrinsically requires
      self-reference. For example, I might be feeling sad, and think that I want
      to feel happy instead. In this case, both the initial state and the target
      state are defined in terms of what I feel, so in order to measure my
      progress, I need to track a reference to myself.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/HappyStates.png"
            class="draft-image center" style="width:66%"></figure>
      </span></div>
    <span> </span>
    <p>In that post, I remarked that changing one’s experience of one’s self may
      change how emotions are experienced. This does not necessarily require
      high levels of enlightenment: it is a common mindfulness practice to
      reframe your emotions as something that is external to you, in which case
      negative emotions might cease to feel aversive. </p>
    <p>I have <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/5gfqG3Xcopscta3st/building-up-to-an-internal-family-systems-model">also
              previously discussed</a></span></span></u> therapy techniques that
      allow you to create some distance between yourself and your feelings,
      making them less aversive. For example, one may pay attention to where in
      their body they feel an emotion, keep their attention on those physical
      feelings, and then allow a visual image of that emotion to arise. This may
      then cause the emotion to be experienced as “not me”, in a way which makes
      it easier to deal with.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/AversiveNonAversiveState.png"
            class="draft-image center" style="width:75%"></figure>
      </span></div>
    <span> </span>
    <p>The next post in my series was on <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/gvXFBaThWrMsSjicD/craving-suffering-and-predictive-processing-three">craving
              and suffering</a></span></span></u>, where I distinguished two
      different kinds of motivation: craving and non-craving. I claimed that
      craving is intrinsically associated with the desire to either experience
      positive valence, or to avoid experiencing negative valence.
      Non-craving-based motivation, on the other hand, can care about anything;
      not just valence.</p>
    <p>In particular, I claimed that discomfort / suffering (unsatisfactoriness,
      to use a generic term) is created by craving: craving attempts to resist
      reality, and in so doing generates an error signal which is subjectively
      experienced as unsatisfactoriness. I also suggested that non-craving-based
      motivation does not resist reality in the same way, so does not create
      unsatisfactoriness.</p>
    <p>Putting some of these pieces together:</p>
    <ul>
      <li>Craving tries to ensure that “the self” experiences positive feelings
        and avoids negative feelings.</li>
      <li>If there are consciously experienced feelings which are not
        interpreted as being experienced by the self, it does not trigger
        craving.</li>
      <li>There is a two-way connection between the sense of self and craving. </li>
      <ul>
        <li>On one hand, experiencing a strong sense of self triggers craving,
          as feelings are interpreted as happening to the self. </li>
        <li>From the other direction, once craving <em>is</em> triggered, it
          sends into consciousness the goal of either avoiding or experiencing
          particular feelings. As this goal is one that requires making
          reference to the self, sending it into consciousness instantiates a
          sense of self.</li>
      </ul>
    </ul>
    <p>Let’s look at this a bit more.</p>
    <h2 id="Craving_as_a_second_layer_of_motivation">Craving as a second layer
      of motivation</h2>
    <p>A basic model is that the brain has subsystems which optimize for
      different kinds of goals, and then produce positive or negative valence in
      proportion to how well those goals are being achieved. </p>
    <p>For example, <u><span><span><span><a href="https://en.wikipedia.org/wiki/Appraisal_theory">appraisal
                theories of emotion</a></span></span></span></u> hold that
      emotional responses (with their underlying positive or negative valence)
      are the result of subconscious evaluations about the significance of a
      situation, relative to the person's goals. An evaluation saying that you
      have lost something important to you, for example, may trigger the emotion
      of sadness with its associated negative valence.</p>
    <p>Or consider a situation where you are successfully carrying out some
      physical activity; playing a fast-paced sport or video game, for example.
      This is likely to be associated with positive valence, which emerges from
      having success at the task. On the other hand, if you were failing to keep
      up and couldn't get into a good flow, you would likely experience negative
      valence.</p>
    <p>Valence looks like a signal about whether some goals/values are being
      successfully attained. A subsystem may have a goal X which it pursues
      independently, and depending on how well it goes, valence is produced as a
      result. In this model, because valence tends to signal states that are
      good/bad for the achievement of an organism's goals, craving acts as an
      additional layer that "grabs onto" states that seem to be particularly
      good/bad, and tries to direct the organism more strongly towards those.</p>
    <p>There’s a subtlety here, in that craving is distinct from negative
      valence, but craving can certainly <em>produce</em> negative valence. For
      example:</p>
    <ul>
      <li>You are feeling stressed out, so you go for a long walk. This helps
        take your mind off the stress, and you come back relaxed.</li>
      <li>The next time you are stressed and feel like you need a break, you
        remember that the walk helped you before. It’s important for you to get
        some more work done today, so you take another walk in the hopes of
        calming down again. As you do, you keep thinking “okay, am I about to
        calm down and forget my worries now” - and this question keeps occupying
        you throughout your walk, so that when you get back home, you haven’t
        actually relaxed at all.</li>
    </ul>
    <p>I think this has to do with craving influencing the goals and inputs that
      are fed into various subsystems. If craving generates the goal of “I
      should relax”, then that goal is taken up by some planning subsystem; and
      success or failure at that goal, may by itself produce positive or
      negative valence just like any other goal does. This also means that
      craving may generate emotions that generate additional craving: first you
      have a craving to relax on a walk, but then going on the walk produces
      frustration, creating craving to be rid of the frustration...</p>
    <p>My model about craving and non-craving seems somewhat similar to the
      proposed distinction between <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/fa5o2tg9EfJE77jEQ/the-human-s-hidden-utility-function-maybe">model-based
              and model-free goal systems</a></span></span></u> in the brain.
      The model-based system does complex reasoning about what to do; it is
      capable of pretty sophisticated analyses, but requires substantial
      computational resources. To save on computation, the model-free system
      remembers which actions have led to good or bad outcomes in the past, and
      tries to repeat/avoid them. Under this model, craving would be associated
      with something like the model-free system, one which used “did an action
      produce positive or negative valence” as a shorthand for whether actions
      should be taken or avoided.</p>
    <p>However, it would be a mistake to view these as two entirely distinct
      systems. <u><span><span><a class="CommentLinkPreviewWithComment-link" href="https://www.lesswrong.com/posts/gvXFBaThWrMsSjicD/craving-suffering-and-predictive-processing-three?commentId=5hQaEZHRFjBJ4Moyk">Research
              suggests</a></span></span></u> that even within the same task,
      both kinds of systems are active, with the brain adaptively learning which
      one of the systems to deploy during which parts of the activity. Craving
      valence and more complex model-based reasoning also seem to be intertwined
      in various ways, such as:</p>
    <ul>
      <li>It is possible to unlearn particular cravings, as the brain updates to
        notice that this specific craving is not actually useful. The unlearning
        process seems to involve some degree of model-based evaluation, as the
        brain seems resistant to release cravings if it predicts that doing so
        would make it harder to achieve some particular goal.</li>
      <li>Model-based subsystems may act in ways that seem to make use of
        craving. For example, in an earlier post <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain">reviewing
                the book Unlocking the Emotional Brain</a></span></span></u>, I
        discussed the example of Richard. A subsystem in his brain predicted
        that if he were to express confidence, people would dislike him, so it
        projected negative self-talk into his consciousness to prevent him from
        being confident. Presumably the self-talk had negative valence and
        caused a craving to avoid it, in a way which contributed to him not
        saying anything. I suspect that this is part of why <u><span><span><span><a
                  href="https://books.google.fi/books?id=medHDwAAQBAJ&amp;lpg=PT8&amp;ots=YoBhBQTtwX&amp;dq=%22Part%20of%20me%20wished%20I%20hadn%E2%80%99t%20seen%20the%20e-mail.%22&amp;pg=PT8#v=onepage&amp;q&amp;f=false">mindfulness
                  practice may release buried trauma</a></span></span></span></u>:
        if you get better at dealing with mild aversion, that aversion might
        previously have been used by subsystems to keep negative memories
        contained - and then your mind gets flooded with really unpleasant
        memories, and much stronger unsatisfactoriness than you were necessarily
        prepared to deal with.</li>
    </ul>
    <p>It is also worth making explicit that pursuing positive valence and
      avoiding negative valence are goals that can be pursued by
      non-craving-based subsystems as well. </p>
    <p>For basically any goal, there can be craving-based and non-craving-based
      motivations. You might pursue pleasure because of a craving for pleasure,
      but you may also pursue it because you value it for its own sake, because
      experiencing pleasure makes your mind and body work better than if you
      were only experiencing unhappiness, because it is useful for releasing
      craving… or for any other reason.</p>
    <h2 id="From_self_to_craving_and_from_craving_to_self">From self to craving
      and from craving to self</h2>
    <p>I have mostly been talking about craving in terms of aversion (craving to
      avoid a negative experience). Let’s look at some examples of craving a
      positive experience instead:</p>
    <ul>
      <li>It is morning and your alarm bell rings. You should get up, but it
        feels nice to be sleepy and remain in bed. You want to hang onto those
        pleasant sensations of sleepiness for a little bit more.</li>
      <li>You are spending an evening together with a loved one. This is the
        last occasion that you will see each other in a long time. You feel
        really good being with them, but a small part of you is unhappy over the
        fact that this evening will eventually end.</li>
      <li>You are at work on a Friday afternoon. Your mind wanders to the
        thought of no longer being at work, and doing the things you had planned
        for the weekend. You would prefer to be done with work already, and find
        it hard to stay focused as you cling to the thoughts of your free time.</li>
      <li>You are single and hanging out with an attractive person. You know
        that they are not into you, but it would be so great if they were. You
        can’t stop thinking about that possibility, and this keeps distracting
        you from the actual conversation.</li>
      <li>You are in a conversation with several other people. You think of a
        line that would be a great response to what someone else just said.
        Before you can say it, somebody says something, and the conversation
        moves on. You find yourself still thinking of your line, and how nice it
        would have been to get to say it.</li>
      <li>You had been planning on going to a famous museum while on your
        vacation, but the museum turns out to be temporarily closed at the time.
        You keep thinking about how much you had been looking forward to it. </li>
      <li>You are hungry, and keep thinking about how good a particular food
        would taste, and how much better you would feel after you had eaten.</li>
    </ul>
    <p>These circumstances are all quite different, but on a certain abstract
      level, they share the same kind of a mechanism. There is the thought of
      something pleasant, which triggers craving, and a desire to either get
      into that pleasant state or make sure you remain in it.</p>
    <p>Let’s say that there is <u><span><span><span><a href="https://en.wikipedia.org/wiki/Prat%C4%ABtyasamutp%C4%81da#Twelve-fold_chain">this
                kind of a process</a></span></span></span></u>:</p>
    <p><em>Sense contact</em>. You have some particular experience, such as the
      sensation of being sleepy and in bed, or the thought of how it would feel
      if the attractive person in front of you were to like you. In third-person
      terms, this sensation/thought is sent to the <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain">global
              workspace</a></span></span></u> of your consciousness.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/RelationshipThought.png"
            class="draft-image center" style="width:40%"></figure>
      </span></div>
    <span> </span>
    <p><em>Valence. </em>An emotional system classifies this experience as
      being positive, and <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/zThWT5Zvifo5qYaca/the-neuroscience-of-pleasure">paints
              it with a corresponding positive gloss</a></span></span></u> as it
      is being broadcast into the workspace.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/RelationshipValence.png"
            class="draft-image center" style="width:40%"></figure>
      </span></div>
    <span> </span>
    <p><em>Craving. </em>A craving subsystem notices the positive valence, and
      interprets the valence as <em>being experienced by you.</em> The
      subsystem registers the imagined state the valence is associated with, so
      it sets the intention of getting the self to achieve that state, and the
      resulting positive valence. For example, it may set the intention of
      getting into a relationship with that attractive person.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/RelationshipTargetState.png"
            class="draft-image center" style="width:40%"></figure>
      </span></div>
    <span> </span>
    <p><em>Clinging and planning. </em>This intent clings in your mind and is
      fed to planning subsystems. They make plans of how to get to the state
      which has been evaluated as being better. (My <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/gvXFBaThWrMsSjicD/craving-suffering-and-predictive-processing-three">previous
              post</a></span></span></u> was largely a description of this
      stage.)</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/RelationshipQuestionmarkPlan.png"
            class="draft-image center" style="width:100%"></figure>
      </span></div>
    <span> </span>
    <p><em>Birth. </em>As these plans are broadcast into consciousness for
      evaluation, they contain a representation of your current state, creating
      a stronger experience of having a distinct self that wants a particular
      thing. Subsystems may emphasize particular aspects of their model of you
      that seem relevant for achieving the goal: for example, if the other
      person seems to be drawn towards musicians, your skill at this may become
      highlighted. Maybe you, being a musical kind of person, could play the
      guitar and make a good impression on them… emphasizing your “musician
      nature” in the self-representation that appears in consciousness.</p>
    <div style="text-align: center;"><span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/Plan.png"
            class="draft-image center" style="width:100%"></figure>
      </span></div>
    <span> </span>
    <p><em>Death. </em>Eventually, you stop pursuing the goal, at least for the
      time being. Maybe you get what you wanted, it turns out to be unviable
      right now, or you just get distracted and forget. This particular
      goal-state and plan disappear from consciousness, and with it, the sense
      of self that was tracking its completion disappears as well. Before long -
      or maybe even simultaneously - another self will be created, one which
      cares about something completely different: maybe you got hungry, and now
      the craving only cares about getting some food, creating a food-hungry
      self...</p>
    <h2 id="Craving_and_the_self_model">Craving and the self-model</h2>
    <p>There’s a straightforward reason for why craving should be tied into a
      conception of the self: its purpose is to motivate <em>you</em> to
      action. If your brain predicts that someone other than you would
      experience positive valence, this does not trigger craving in the same
      way. (Imagine getting the one thing that you most desire at the moment.
      Then imagine some complete stranger getting a similar thing. Not quite the
      same, is it?)</p>
    <p>Your craving subsystems have been wired to make <em>you</em> experience
      positive valence / avoid negative valence. Each craving subsystem contains
      an implicit schema along the lines of “<em>I </em>will strive towards a
      more positive experience, and then <em>I </em>will have that more
      positive experience in the end”. If a craving subsystem predicted that its
      actions would produce someone <em>else</em> a more positive experience,
      this would not fulfill the goal condition in that schema. (Of course,
      craving may have the instrumental goal of making someone else happy, if it
      predicts that leads to a positive consequence for you.)</p>
    <p>At the same time, there is something interesting going on with the fact
      that mindfulness and cognitive defusion practices work: if you can
      mentally transform a source of negative valence into something that feels
      external to you, it may not bother you as much. In particular, it feels
      like you don’t need to react to it: that is, there is less of a craving to
      get it out of your consciousness. The inference of “if I get this emotion
      out of my mind, I will feel better” is never applied, as the emotion is
      not experienced as being “in my mind” in the first place.</p>
    <p>In other words, the mere experience or prediction of positive/negative
      valence alone does not seem to be enough to trigger craving. The valence
      also needs to be bound into a particular abstract representation of the
      self, and interpreted as happening to “you”.</p>
    <p>At this point, we need to distinguish between two different senses of
      “happening to you”:</p>
    <ul>
      <li>Happening to the system defined by the physical boundaries of your
        body; for conscious experiences, appearing in the global workspace
        located within that body. I will call this “happening to the system”.</li>
      <li>Happening to “the self”, an abstract tag which is computed within the
        system, and which feels like the entity that internal experiences such
        as emotions happen <em>to</em>; typically only includes <em>part</em>
        of the content in the global workspace. I will call this “happening to
        the self-model”.</li>
    </ul>
    <p>Craving reacts to valence that is experienced by the self-model. It may <em>seem</em>
      to also react to events that happen to the system, such as getting to
      sleep for longer, but this always takes place through something that
      bottoms out at the self-model experiencing valence. E.g. the thought of
      sleeping longer creates positive valence, and the craving reacts to the
      positive valence becoming incorporated in the self-model. (At the same
      time, the predictions that craving is based on are not necessarily
      accurate or <span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/2MD3NMLBPCqPfnfre/cached-thoughts">up
            to date</a></span></span>, so there is also craving for things that
      we do not actually enjoy.)</p>
    <p>At the same time, non-craving-based motivation may react to anything,
      including events that happen to the system rather than the self-model.
      Even if the thought of getting to sleep for longer didn't cause craving,
      you could still stay in bed in order to get more rest. Because this
      involves some degree of abstract reasoning, craving is probably something
      that humans need to have in place <em>before</em> non-craving-based
      systems have had a chance to mature and acquire sophisticated models. A
      toddler is not capable of intellectually figuring out the consequences of
      most harmful things and how they should thus be avoided, but the toddler <em>does</em>
      still have visceral craving to avoid pain.</p>
    <p>Earlier in this series, I mentioned a metaphor of experiencing yourself
      as the sky, and all the emotions and thoughts as things that are on the
      sky but which do not affect the sky. This was intended as a metaphor for
      how it feels once your mind comes to identify with your underlying field
      of consciousness, as opposed to the contents of that consciousness. I
      noted that this raised a question which I promised to come back to: why
      would this kind of a shift in identification reduce suffering?</p>
    <p>What I have outlined above suggests an answer: because craving subsystems
      are activated by a prediction of positive or negative valence being
      experienced by the self-model. If the system’s self-model changes so that
      experiences are no longer interpreted as happening to the self-model,
      craving will not trigger, nor will it produce a feeling of
      unsatisfactoriness. At the same time, non-craving-based motivation can
      still reason about the consequences of those events and respond
      appropriately.</p>
    <p>In these articles, I have used the term “no-self”, because that seems to
      be the established translation for <em><span><span><span><a href="https://en.wikipedia.org/wiki/Anatta">anatta</a></span></span></span></em>;
      but I could also have used the arguably better translation of“<em>not</em>
      self”. </p>
    <p>In other words, the brain has something of a built-in model defining what
      kinds of criteria a piece of conscious experience needs to fulfill in
      order to be incorporated into the self-model. With sufficiently close
      study, one may come to notice the way in which actually <em>no</em>
      conscious content fulfills this criteria: there is nothing in
      consciousness that is “self”... and if there is nothing that is
      incorporated into the self-model, then there is nothing that could trigger
      craving.</p>
    <p>At the same time, some “no-self” experiences also seem to also be
      interpreted as “everything is self” rather than “nothing is self”. For
      example, my <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/W59Nb72sYJhMJKGB8/a-non-mystical-explanation-of-no-self-three-characteristics">earlier
              post on no-self</a></span></span></u> quoted an experience
      described as "<em>this is all me [...] my identity is literally everything
        that I could see through my eyes</em>". Craving also seems reduced in
      these situations.</p>
    <p>With emotions, the raw experience of the emotion is distinct from the
      process of naming the emotion; the same emotion may have different names
      in different languages. Likewise, the subsystem which creates the abstract
      boundary that craving responds to, and the subsystem which produces the
      verbal label of that boundary, may be distinct. Thus, if the experience of
      a boundary dividing self and non-self disappears, then this might on a
      verbal level be interpreted as either “all is self” <em>or</em> “nothing
      is self”, depending on <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/7HY8HaRdFFnpeT9gx/highlights-from-integral-spirituality#Quotes_on_Spirituality">which
              framework</a></span></span></u> one is using and which features of
      the experience one is paying attention to.</p>
    <p><em> <em><strong>Note:</strong> Some of the stick figures and musical
          notes in this post were borrowed from xkcd.com. <br>
        </em></em></p>
    <p><em><em><br>
        </em></em></p>
    <div>
      <h1 id="On_the_construction_of_the_self">On the construction of the self</h1>
      <p>In his essay <u><span><span><span><a href="https://ase.tufts.edu/cogstud/dennett/papers/selfctr.pdf">The
                  Self as a Center of Narrative Gravity</a></span></span></span></u>,
        Daniel Dennett offers the thought experiment of a robot that moves
        around the world. The robot also happens to have a module writing a
        novel about someone named Gilbert. When we look at the story the
        novel-writing module is writing, we notice that its events bear a
        striking similarity to what the rest of the robot is doing:</p>
      <blockquote>If you hit the robot with a baseball bat, very shortly
        thereafter the story of Gilbert includes his being hit with a baseball
        bat by somebody who looks like you. Every now and then the robot gets
        locked in the closet and then says "Help me!" Help whom? Well, help
        Gilbert, presumably. But who is Gilbert? Is Gilbert the robot, or merely
        the fictional self created by the robot? If we go and help the robot out
        of the closet, it sends us a note: "Thank you. Love, Gilbert." At this
        point we will be unable to ignore the fact that the fictional career of
        the fictional Gilbert bears an interesting resemblance to the "career"
        of this mere robot moving through the world. We can still maintain that
        the robot's brain, the robot's computer, really knows nothing about the
        world; it's not a self. It's just a clanky computer. It doesn't know
        what it's doing. It doesn't even know that it's creating a fictional
        character. (The same is just as true of your brain; it doesn't know what
        it's doing either.) Nevertheless, the patterns in the behavior that is
        being controlled by the computer are interpretable, by us, as accreting
        biography--telling the narrative of a self.</blockquote>
      <p>As Dennett suggests, something similar seems to be going on in the
        brain. Whenever you are awake, there is a constant distributed
        decision-making process going on, where different subsystems swap in and
        out of control. While you are eating breakfast, subsystem #42 might be
        running things, and while you are having an argument with your spouse,
        subsystem #1138 may be driving your behavior. As this takes place, a
        special subsystem that we might call the “self-narrative subsystem”
        creates a story of how all of these actions were taken by “the self”,
        and writes that story into consciousness.</p>
      <p>The consciously available information, including the story of the self,
        is then used by subsystems in the brain to develop additional models of
        the system’s behavior. There is an experience of boredom, and “the self”
        seems to draw away from the boredom - this may lead to the inference
        that boredom is bad for the self, and something that needs to be
        avoided. An alternative inference might have been that there is a
        subsystem which reacts to boredom by avoiding it, while other subsystems
        don’t care. So rather than boredom being intrinsically bad, one
        particular subsystem has an avoidance reaction to it. But as long as the
        self-narrative subsystem creates the concept of a self, the notion of
        there being a single self doing everything looks like the simplest
        explanation, and the system tends to gravitate towards that
        interpretation.</p>
      <p>In the article “<u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/ZiQqsgGX6a42Sfpii/the-apologist-and-the-revolutionary">The
                Apologist and the Revolutionary</a></span></span></u>”, Scott
        Alexander discusses neuroscientist V.S. Ramachandran’s theory that the
        brain contains a reasoning module which attempts to fit various
        observations into the brain’s “current best guess” of what’s going on.
        He connects this theory with the behavior of “split-brain” patients, who
        have had the connection between the hemispheres of their brain severed:</p>
      <blockquote>Consider <u><span><span><span><a href="http://books.google.ie/books?id=_rkKxbevFZEC&amp;pg=PA10&amp;lpg=PA10&amp;dq=split-brain+chicken+shovel&amp;source=bl&amp;ots=9gVX7xBkJq&amp;sig=yKnpOKg1jdzifungp7VgIXMLMcA&amp;hl=en&amp;ei=muu2SZKXA-LBjAeupOCvCQ&amp;sa=X&amp;oi=book_result&amp;resnum=8&amp;ct=result">the
                  following experiment</a></span></span></span></u>: a
        split-brain patient was shown two images, one in each visual field. The
        left hemisphere received the image of a chicken claw, and the right
        hemisphere received the image of a snowed-in house. The patient was
        asked verbally to describe what he saw, activating the left (more
        verbal) hemisphere. The patient said he saw a chicken claw, as expected.
        Then the patient was asked to point with his left hand (controlled by
        the right hemisphere) to a picture related to the scene. Among the
        pictures available were a shovel and a chicken. He pointed to the
        shovel. So far, no crazier than what we've come to expect from
        neuroscience.</blockquote>
      <blockquote>Now the doctor verbally asked the patient to describe why he
        just pointed to the shovel. The patient verbally (left hemisphere!)
        answered that he saw a chicken claw, and of course shovels are necessary
        to clean out chicken sheds, so he pointed to the shovel to indicate
        chickens. The apologist in the left-brain is helpless to do anything
        besides explain why the data fits its own theory, and its own theory is
        that whatever happened had something to do with chickens, dammit!</blockquote>
      <p>Now, as people have pointed out, it is tricky to use split-brain cases
        to draw conclusions about people who have not had their hemispheric
        connections severed. But this case looks <em>very</em> similar to what
        meditative insights suggest, namely that the brain constructs an ongoing
        story of there being a single decision-maker. And while the story of the
        single self tends to be closely correlated with the system’s actions,
        the narrative self does not actually <em>decide</em> the person’s
        actions, it's just a story of someone who does. In a sense, the part of
        your mind that may feel like the “you” that takes actions, is actually
        produced by a module that just <em>claims</em> <em>credit</em> for
        those actions.</p>
      <p>With sufficiently close study of your own experience, you may notice
        how these come apart, and what creates the appearance of them being the
        same. As you accumulate more evidence about their differences, it
        becomes harder for the system to consistently maintain the hypothesis
        equating them. Gradually, it will start revising its assumptions.</p>
      <p>Some of this might be noticed without any meditation experience. For
        example, suppose that you get into a nasty argument with your spouse,
        and say things that you don’t fully mean. The next morning, you wake up
        and feel regret, wondering why in the world you said those terrible
        things. You resolve to apologize and not do it again, but after a while,
        there is another argument and you end up behaving in the same nasty way.</p>
      <p>What happened was something like: something about the argument
        triggered a subsystem which focused your attention on everything that
        could be said to be wrong with your spouse. The following morning, that
        particular trigger was no longer around: instead, there was an
        unpleasant emotion, guilt. The feelings of guilt activated another
        subsystem which had the goal of making <em>those</em> sensations go
        away, and it had learned that self-punishment and deciding to never act
        the same way is an effective way of doing so. (As an aside, Chris Frith
        and Thomas Metzinger <u><span><span><span><a href="https://scholar.google.fi/scholar?cluster=6410448901910095955&amp;hl=en&amp;as_sdt=0%2C5">speculate
                  that</a></span></span></span></u> one of the reasons why we
        have a unified self-model, is to allow this kind of a social regret and
        a feeling of “I could have done otherwise”.)</p>
      <p>In fact, the “regretful subsystem” cannot directly influence the “nasty
        subsystem”. The regretful subsystem can only output the thought that <em>it</em>
        will not act in a nasty way again - which it never did in the first
        place. Yet, because the mind-system has the underlying modeling
        assumption of being unified, the regretful subsystem will (correctly)
        predict that <em>it</em> will not act in that nasty way, if put into
        the same situation again… while failing to predict that it will actually
        be the <em>nasty</em> subsystem that activates, because the regretful
        subsystem is currently <em>identifying</em> <em>with </em>(modeling
        itself as having caused) the actions that were actually caused by the
        nasty subsystem.</p>
      <p>Having an intellectual understanding of this may sometimes help, but
        not always. Suppose that you keep feeling strong shame over what
        happened and a resolve never to do so again. At the same time, you
        realize that you are not thinking clearly about this, and that you are
        not actually a unified self. Your train of thought might thus go
        something like this:</p>
      <p>“Oh God why did I do that, I feel so ashamed for being such a horrible
        person… but aaah, it’s pointless to feel shame, the subsystem that did
        that wasn’t actually the one that is running now, so this isn’t helping
        change my behavior… oh man oh man oh man I’m such a terrible person I
        must never do that again… but that thought <em>doesn’t actually help</em>,
        it doesn’t influence the system that actually did it, I must do
        something else… aaaahh why did I do that I feel so much shame…”</p>
      <p>Which we can rewrite as:</p>
      <p><strong>Regretful subsystem:</strong> “Oh God why did I do that, I feel
        so shamed for being such a horrible person…”</p>
      <p><strong>“Sophisticated” subsystem:</strong> “But aaah, it’s pointless
        to feel shame, the subsystem that did that wasn’t actually the one that
        is running now…”</p>
      <p><strong>Regretful subsystem:</strong> “Oh man oh man oh man I’m such a
        terrible person I must never do that again…”</p>
      <p><strong>“Sophisticated” subsystem:</strong> “But that thought <em>doesn’t
          actually help</em>, it doesn’t influence the subsystem that actually
        did it, so I must do something else…”</p>
      <p><strong>Regretful subsystem:</strong> “Aaaahh why did I do that, I feel
        so much shame…”</p>
      <p>I previously said that the regretful subsystem cannot directly affect
        the nasty subsystem… but it may very well be that a more sophisticated
        subsystem, which understands what is happening, cannot directly
        influence the regretful subsystem <em>either</em>. Even as it
        understands the disunity of self on one level, it may still end up
        identifying with all the thoughts currently in consciousness. </p>
      <p>In fact, the “sophisticated” subsystem may be particularly <em>likely</em>
        to assume that the mind is unified.</p>
      <p>Suppose that the regretful subsystem triggers first, and starts
        projecting self-punishment into the global workspace. This then triggers
        another subsystem, which has learned that “a <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/E4zGWYzh6ZiG85b2z/the-curse-of-the-counterfactual">subsystem
                triggering to punish myself</a></span></span></u> is not
        actually going to change my future actions, and it would be more useful
        for me to do something else”. In other words, even as the philosophical
        subsystem’s <em>strategy</em> is to <em>think really hard about the
          verbal concept of no-self</em>, the subsystem <em>has actually been</em>
        triggered by the thought of “I am ashamed”, and has the goal state of
        making the “me” not feel shame. It even ends up thinking “I must do
        something else”, as if the shameful thoughts were coming from <em>it</em>
        rather than a different subsystem. Despite a pretense of understanding
        no-self, its actual cognitive schema is still identifying with the
        regretful system’s output.</p>
      <div style="text-align: center;"><span>
          <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/AvoidShame.png"
              class="draft-image center" style="width:100%"></figure>
        </span></div>
      <span> </span></div>
    <p>This is one of the trickiest things about no-self experiences: on some
      occasions, you might be able to get into a state with no strong sense of
      self, when you are not particularly trying to do so and don’t have strong
      <span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/r6kzvdia4S8TKE6WF/from-self-to-craving-three-characteristics-series">craving</a></span></span>.
      The resulting state then feels really pleasant. You might think that this
      would make it easier to let go of craving in the future… and it might in
      fact make you more motivated to let go of craving again, but “more
      motivated” frequently means “have more craving to let go of craving”. Then
      you need to find ways to disable <em>those</em> subsystems - but of
      course, if you have the <em>goal</em> of disabling the subsystems, then
      this may mean that you have craving to let go of the craving to let go of
      the craving…</p>
    <h2 id="Mechanisms_of_claiming_credit">Mechanisms of claiming credit</h2>
    <p>Consider someone who is trying hard to concentrate on a lecture (or on
      their meditation object), but then wanders off into a daydream without
      noticing it. Thomas Metzinger calls the moment of drifting off to the
      daydream a “<u><span><span><span><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2013.00931/full">self-representational
                blink</a></span></span></span></u>”. As the content of
      consciousness changes from that produced by one subsystem to another,
      there is a momentary loss of self-monitoring that allows this change to
      happen unnoticed.</p>
    <p>From what I can tell, the mechanism by which the self-narrative agent
      manages to disguise itself as the causally acting agent seems to also
      involve a kind of a self-representative blink. Normally, <u><span><span><span><a
                href="https://www.mctb.org/mctb2/table-of-contents/part-vi-my-spiritual-quest/70-around-the-world-and-finding-home/agencylessness/"><em>intentions</em>
                precede</a></span></span></span></u> both physical and mental
      actions: before moving my hand I have an intention to move my hand, before
      pursuing a particular line of thought I have an intention to pursue that
      line of thought, and before moving my attention to my breath I have an
      intention to move my attention to my breath. Just as these intentions
      appear, there is a blink in awareness, making it hard to perceive what
      exactly happens. That blink is used by the self-narrative agent to
      attribute the intention as arising from a single “self”.</p>
    <p>If one develops sufficient introspective awareness, they may come to see
      that the intentions are arising on their own, and that there is actually
      no way to control them: if one <em>intends</em> to control them somehow,
      then the intention to do that is also arising on its own. Further, it can
      become possible to see exactly what the self-narrative agent is doing, and
      how it creates the story of an independent and acausal self. This does not
      eliminate the self-narrative agent, but does allow its nature to be
      properly understood, as it is more clearly seen. Meditation teacher Daniel
      Ingram <u><span><span><span><a href="https://parletre.wordpress.com/2019/06/22/daniel-ingram-response/">describes</a></span></span></span></u>
      this as the nature of the self-representation “becoming bright, clear,
      hardwired to be perceived in a way that doesn’t create habitual
      misperception”; <u><span><span><span><a href="https://parletre.wordpress.com/2019/06/25/response-to-ingram-3/#comment-66">and
                elaborates</a></span></span></span></u>:</p>
    <blockquote>The qualities that previously meant and were perceived to be
      “Agent” still arise in their entirety. Every single one of them. Their
      perceptual implications are very different, but, functionally, their
      meanings are often the same, or at least similar. [...]</blockquote>
    <blockquote>All thoughts arise in this space. They arise simultaneously as
      experiences (auditory, physical, visual, etc.), but also as meaning. These
      meanings include thoughts and representations such as “I”, “me”, and
      “mine” just the way they did before. No meaning have been cut off.
      Instead, these meanings are a lot easier to appreciate as they arise for
      being the representations that they are, and also there is a perspective
      on this representation that is refreshingly open and spacious rather than
      being contracted into them as happened before.</blockquote>
    <h2 id="No_self_and_paradoxes_around__doing_">No-self and paradoxes around
      “doing”</h2>
    <p>Some meditation instructions may say nonsensical-sounding things that go
      roughly as follows: “Just sit down and don’t do anything. But also don’t
      try to not do anything. You should neither do anything, nor do ‘not doing
      anything’.”</p>
    <p>Or <u><span><span><span><a href="https://kennethfolkdharma.com/quick-start-guide/">they
                might say</a></span></span></span></u>: “Surrender entirely.
      This moment is as it is, with or without your participation. This does not
      mean that you must be passive. Surrender also to activity.”</p>
    <p>This sounds confusing, because our normal language is built around the
      assumption of a unitary self which only engages in voluntary,
      intentionally chosen activities. But it turns out that if you <em>do</em>
      just sit down and decide to let whatever thoughts arise in your head, you
      might soon start having confusing experiences. </p>
    <p>Viewed from a multi-agent frame, there is no such thing as “not making
      decisions”. Different subsystems are constantly transmitting different
      kinds of intentions - about what to say, what to do, and even what to
      think - into consciousness. Even things which do not subjectively <em>feel</em>
      like decisions, like just sitting still and waiting, are still the
      outcomes of a constant decision-making process. It is just that a
      narrative subsystem tags <em>some</em> outcomes as being the result of
      “you” having made a decision, while tagging others as things that “just
      happened”. </p>
    <p>For example, if an unconscious evidence-weighting system decides to bring
      a daydream into consciousness, causing your mind to wander into the
      daydream, you may feel that you “just got lost in thought”. But when a
      thought about making tea comes into consciousness and you then get up to
      make tea, you may feel like you “decided to make some tea”. Ultimately,
      you have a schema which classifies everything as either “doing” or “not
      doing”, and attempts to place all experience into one of those two
      categories.</p>
    <p>Various paradoxical-sounding meditation instructions about doing
      ”nothing” sound confusing because they are intended to get you to notice
      things that do not actually match these kinds of assumptions.</p>
    <p>For example, you may be told to just sit down and let your mind do
      whatever it wants, neither controlling what happens in your mind but also
      not trying to avoid controlling it. <u><span><span><span><a href="https://www.youtube.com/watch?v=cZ6cdIaUZCA&amp;t=12s">Another
                way of putting this is</a></span></span></span></u>:</p>
    <ul>
      <li>Do not exert any conscious intention to control your mind, such as by
        preventing yourself from thinking particular thoughts.</li>
      <li>But if you notice a sensation of yourself trying to control your mind,
        also do not do anything to stop yourself from feeling that sensation.</li>
    </ul>
    <p>One thing (of many) that may happen when you try to follow these
      instructions is:</p>
    <ul>
      <li>You were told not to have any conscious intention to control your
        mind, so the subsystems that caused you to sit down and start
        meditating, take no particular action to shift the contents of
        consciousness.</li>
      <li>At some point, other subsystems, driven by a priority other than
        meditating, send something into consciousness. They are attempting to
        change its contents towards the particular priority that these
        subsystems care about.</li>
      <li>This is noticed by the subsystem classifying mental contents as doing
        or non-doing. It classifies this as “doing”, and sends a sensation of
        intentional “doing” into consciousness.</li>
      <li>The subsystem which originally sat down with the intention of
        meditating and not exerting conscious control, notices the sensation of
        conscious doing.</li>
      <li>The overall mind-system gets confused, because its internal narrative
        (modeled from the assumption of a unitary self) now says “I sat down and
        intended not to intentionally control my mind, but now I find myself
        intentionally controlling my mind anyway, but how can I unintentionally
        end up doing something intentional?”</li>
      <li>Following the original instructions, the non-meditating subsystem may
        now just let the sensation of conscious doing be there, without
        interfering with it.</li>
      <li>Eventually, there may be an experiential realization that the
        sensation of intentional doing is just a sensation or a tag assigned to
        some particular actions, not intrinsically associated with any single
        subsystem.</li>
    </ul>
    <p>So, translated into multiagent language: “don’t do anything but also
      don’t not do anything” means “you, the subsystem which is following these
      instructions: don’t do anything in particular, but when an intention to do
      something arises from another subsystem, also don’t do anything to
      counteract that intention”. </p>
    <p>Inevitably, you will experience yourself as doing something anyway,
      because another subsystem has swapped in and out of control, and this
      registers to you as 'you' having done something. This is an opportunity to
      notice on an experiential level that you are actually identifying with
      multiple distinct processes at the same time.</p>
    <p>(This is very much a simplified account; in actuality, even the
      “meditating subsystem” seems itself composed of multiple smaller
      subsystems. As the degree of mental precision grows, every component in
      the mind will grow increasingly fine-grained. This makes it difficult to
      translate things into a coarser ontology which does not draw equal
      distinctions.)</p>
    <h2 id="The_difficulty_of_surrendering">The difficulty of surrendering</h2>
    <p>Contemplative traditions may make frequent reference to the concept of
      “surrendering” to an experience. One way that surrender may happen is when
      a subsystem has repeatedly tried to resist or change a particular
      experience, failed time after time, and finally just turns off. (It is
      unclear to me whether this is better described as “the subsystem gives up
      and turns off” or “the overall system gives up on this subsystem and turns
      it off”, but I think that it is probably the latter, even if the
      self-narrative agent may sometimes make it feel like the former.) Once one
      genuinely surrenders to the experience of (e.g.) pain with no attempt to
      make it stop, it ceases to be aversive.</p>
    <p>However, this tends to be hard to repeat. Suppose that a person manages
      to surrender to the pain, which makes it stop. The next time they are in
      pain, they might remember that “I just need to surrender to the pain, and
      it will stop”. </p>
    <p>In this case, a subsystem which is trying to get the pain out of
      consciousness has formed the prediction that there <em>is</em> an action
      that can be carried out to make the pain stop. Because the self-narrative
      agent records all actions as “I did this”, the act of surrendering to the
      pain has been recorded in memory as “I surrendered to the pain, and that
      made it stop”. </p>
    <p>The overall system has access to that memory; it infers something like
      “there was an action of ‘surrender’ which I carried out, in order to make
      the pain stop; I must carry out this action of surrender again”. Rather
      than inferring that there is nothing which can be done to make the pain
      stop, making it useless to resist, the system may reach the <em>opposite</em>
      conclusion and look <em>harder</em> for the thing that it did the last
      time around.</p>
    <p>The flaw here is that “surrendering” was not an <em>action which the
        resisting subsystem took</em>; surrendering was the <em>act of the
        resisting subsystem going offline</em>. Unfortunately, for as long as
      no-self has not been properly grasped, the mind-system does not have the
      concept of a subsystem going offline. Thus, successfully surrendering to
      the pain on a few occasions can make it temporarily <em>harder</em> to
      surrender to it. </p>
    <p>And again, having an intellectual understanding of what I wrote just
      means that there is a subsystem that can detect that the resisting
      subsystem keeps resisting when it should surrender. It can then inject
      into consciousness the thought, “the resisting subsystem should
      surrender”. But this is just another thought in consciousness, and the
      resisting subsystem does not have the capacity to parse verbal arguments,
      so the verbal understanding may become just another system resisting the
      mind’s current state.</p>
    <p>At some point, you begin to surrender to the fact that even if you have
      deep equanimity at the moment, at some point it will be gone. “You” can’t
      maintain equanimity at all times, because there is no single “you” that
      could maintain it, just subsystems which have or have not internalized
      no-self.</p>
    <p>Even if the general sense of self has been strongly weakened, it looks
      like craving subsystems run on <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/2MD3NMLBPCqPfnfre/cached-thoughts">cached
              models</a></span></span></u>. That is to say, if a craving
      subsystem was once created to resist a particular sensation under the
      assumption that this is necessary for protecting a self, that assumption
      and associated model of a self will be stored within that subsystem. The
      craving subsystem may still be triggered by the presence of the sensation
      - and as the subsystem then projects its models into consciousness, they
      will include a strong sense of self again.</p>
    <p>There is an interesting connection between this and <u><span><span><span><a
                href="https://www.sciencedirect.com/science/article/pii/S1364661319300610">Botvinick
                et al. (2019)</a></span></span></span></u>, who discuss a
      brain-inspired artificial intelligence approach. “Episodic
      meta-reinforcement learning” is an approach where a neural network is
      capable of recognizing situations that it has encountered before. When it
      does, the system reinstates the network state that it was in when it was
      in this situation before, allowing old learning to be rapidly retrieved
      and reapplied.</p>
    <p>The authors argue that this model of learning applies to the brain as
      well. If true, it would be compatible with models suggesting that <u><span><span><a
              class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/i9xyZBS3qzA8nFXNQ/book-summary-unlocking-the-emotional-brain">emotional
              learning needs to be activated to be updated</a></span></span></u>;
      and it would explain why craving can persist and be triggered even after
      global beliefs about the self have been revised. Once a person encounters
      a situation which triggers craving, that triggering may effectively
      retrieve from memory a partial “snapshot” of what their brain was like on
      previous occasions when this particular craving triggered… and that
      snapshot may substantially predate the time when the person became
      enlightened, carrying with it memories of past self-models.</p>
    <p>People who have made significant progress on the path of enlightenment
      say that once you have seen through how the sense of self is constructed,
      it becomes <em>possible</em> to remember what the self really is,
      snapping out of a triggered state and working with the craving so that it
      won’t trigger again. But you need to actually <em>remember</em> to do so
      - that is to say, the triggered system needs to grow less activated and
      allow other subsystems better access to consciousness. Over time,
      remembering will grow more frequent and the “periods of forgetting” will
      grow shorter, but forgetting will still keep happening.</p>
    <p>Managing to have a period of equanimity means that you can maintain a
      state where nothing triggers craving, but then maybe your partner yells at
      you and a terrified subsystem triggers and then you scream back, until you
      finally remember and have equanimity again. And at some point you just
      surrender to the fact that this, too, is inevitable, and come to crave
      complete equanimity less. (Or at least, you remember to surrender to this
      some part of the time.)</p>
    <h2 id="An_example_of_a_no_self_experience">An example of a no-self
      experience</h2>
    <p>There was one evening when I had done quite a lot of investigation into
      no-self but wasn’t really thinking about the practice. I was just chatting
      with friends online and watching YouTube, when I had a sense of a mental
      shift, as if a chunk of the sense of having a separate self fell away.</p>
    <p>I'd previously had no-self experiences in which I'd lost the sense of
      being the one doing things, and instead just watched my own thoughts and
      actions from the side. However, those still involved the experience of a
      separate observer, just one which wasn't actively involved in doing
      anything. This was the first time that that too fell away (or at least the
      first time if we exclude brief moments in the middle of conventional flow
      experiences).</p>
    <p>There was also a sense of some thoughts - of the kind which would usually
      be asking things like "what am I doing with my life" or "what do others
      think of me" - starting to feel a little less natural, as if my mind was
      having difficulties identifying the subject that the "I" in those
      sentences was referring to. I became aware of this from having a sense of
      absence, as if I'd been looping those kinds of thoughts on a subconscious
      level, but then had those loops disrupted and only became aware of the
      loops once they disappeared.</p>
    <p>The state didn't feel particularly dramatic; it was nice, but maybe more
      like "neutral plus" than "actively pleasant". After a while in the state,
      I started getting confused about the extent to which the sense of a
      separate self really had disappeared; because I started again picking up
      sensations associated with that self. But when my attention was drawn to
      those sensations, their interpretation would change. They were still the
      same sensations, but an examination would indicate them to be just
      instances of a familiar sensation, without that sensation being
      interpreted as indicating the existence of a self. Then the focus of my
      attention would move elsewhere, and they would start feeling a bit more
      like a self again, when I wasn’t paying so much attention to the
      sensations just being sensations.</p>
    <p>A couple of hours later, I went to the sauna by myself; I had with me a
      bottle of cold water. At some point I was feeling hot but didn't feel like
      drinking more water, so instead I poured some of it on my body. It felt
      cold enough to be aversive, but then I noticed that the aversiveness
      didn't make me stop pouring more of it on myself. This was unusual;
      normally I would pour some of it on myself, go "yikes", and stop doing it.</p>
    <p>This gave me the idea for an experiment. I'd previously thought that
      taking cold showers could be nice mindfulness exercise, but hadn't been
      able to make myself actually take really cold ones; the thought had felt
      way too aversive. But now I seemed to be okay with doing aversive things
      involving cold water.</p>
    <p>Hmm.</p>
    <p>After I was done in the sauna, I went to the shower, with the pressure as
      high and the temperature as cold as it went. The thought of stepping into
      it did feel aversive, but not quite as strongly aversive as before. It
      only took me a relatively short moment of hesitation before I stepped into
      the shower.</p>
    <p>The experience was... interesting. On previous occasions when I'd
      experimented with cold showers, my reaction to a sudden cold shock had
      been roughly "AAAAAAAAAAA I'M DYING I HAVE TO GET OUT OF HERE". And if you
      had been watching me from the outside, you might have reasonably concluded
      that I was feeling the same now. Very soon after the water hit me, I could
      feel myself gasping for breath, the water feeling like a torrent on my
      back that forced me down on my knees, my body desperately trying to avoid
      the water. The shock turned my heartbeat into a frenzied gallop, and I
      would still have a noticeably elevated pulse for minutes after I’d gotten
      out of the shower.</p>
    <p>But I'm not sure if there was any point where I actually felt <em>uncomfortable</em>,
      this time around. I did have a moderate desire to step out of the shower,
      and did give into it after a pretty short while because I wasn't sure for
      how long this was healthy, but it was kind of like... like any discomfort,
      if there was any, was being experienced by a different mind than mine. </p>
    <p>Eventually I went to bed, and my state had become more normal in the
      morning, the mind having returned to a previous mode of functioning. </p>
    <p>The way I described it afterwards, was that in that state, there was an
      awareness of how the sense of self felt like “the glue binding different
      experiences together”. Normally, there might be a sensation of cold, a
      feeling of discomfort, and a thought about the discomfort. All of them
      would be bound together into a single experience of “I am feeling cold,
      being uncomfortable, and thinking about this”. But without the sense of
      self narrating how they relate to each other, they only felt like
      different experiences, which did not automatically compel any actions. In
      other words, craving did not activate, as there was no active concept of a
      self that could trigger it.</p>
    <p>This is related to <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/W59Nb72sYJhMJKGB8/a-non-mystical-explanation-of-no-self-three-characteristics">my
              earlier discussion</a></span></span></u> of the sensations of a
      self as a spatial tag. I mentioned that you might have a particular
      sensation around or behind your eyes - such as some physical sense of
      tension - which is interpreted as “you” looking out from behind your eyes
      and seeing the world. When the sense of self is active, the physical
      sensations are bound together: there is a sensation of seeing, a sensation
      of physical tension, and the self-narrative agent interpreting these as
      “the sensation of tension is the self, which is experiencing the sensation
      of seeing”. Without that linkage, experience turns into just a sensation
      of seeing and a sensation of tension, leaving out the part of a separate
      entity experiencing something.</p>
    <div>
      <h1 id="Impermanence">Impermanence</h1>
      <p>Like no-self and unsatisfactoriness, impermanence seems like a label
        for a broad cluster of related phenomena. A one-sentence description of
        it, phrased in experiential terms, would be that “<u><span><span><span><a
                  href="https://mctb.org/mctb2/table-of-contents/part-i-the-fundamentals/5-the-three-characteristics/">All
                  experienced phenomena, whether physical or mental, inner or
                  outer, are impermanent</a></span></span></span></u>”. </p>
      <p>As an intellectual claim, this does not sound too surprising: few
        people would seriously think that either physical things or mental
        experiences last forever. However, there are ways in which impermanence
        does contradict our intuitive assumptions.</p>
      <p>A conventional example of this is <u><span><span><span><a href="https://en.wikipedia.org/wiki/Change_blindness">change
                  blindness</a></span></span></span></u>. In a typical change
        blindness experiment, people report having good awareness of the details
        of a picture shown to them: but when details are changed during an eye
        saccade, subjects fail to notice any difference. Maybe a person’s hat
        looks red, and people who have been looking <em>right at</em> the hat
        fail to notice that it looked green just a second ago: the consciousness
        of the green-ness has vanished, replaced entirely with red. </p>
      <p>People are typically surprised by this, thinking that “if it was red a
        second ago, surely I would remember that” - a thought that implicitly
        assumes that sense percepts leave permanent memories behind. But as long
        something does not explicitly store a piece of conscious information, it
        is gone as soon as it has been experienced.</p>
      <p>This is a natural consequence of the Global Neuronal Workspace (GNW)
        model of consciousness from neuroscience. As I <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain">have
                previously discussed</a></span></span></u>, studies suggest that
        the content of consciousness corresponds to information held in a
        particular network of neurons called the "global workspace". This
        workspace can only hold a single piece of conscious content at a time,
        and new information is constantly trying to enter it, replacing the old
        information.</p>
      <p>Now if the content of your consciousness happens to be something like
        this:</p>
      <ul>
        <li>0 milliseconds: Seeing a red hat</li>
        <li>53 milliseconds: Thinking about cookies</li>
        <li>200 milliseconds: Seeing a green hat</li>
      </ul>
      <p>Then at the 200 millisecond mark, unless some memory system happened to
        explicitly store the fact of seeing a red hat before, no trace of it
        remains in consciousness for the person to compare with. One can train
        particular subsystems to monitor the contents of consciousness and send
        occasional summaries of previous contents, which is part of what
        investigating impermanence involves.</p>
      <p>Compare this to meditation teacher <u><span><span><span><a href="https://mctb.org/mctb2/table-of-contents/part-i-the-fundamentals/5-the-three-characteristics/">Daniel
                  Ingram’s description of impermanence</a></span></span></span></u>:</p>
      <blockquote>Absolute transience is truly the actual nature of experiential
        reality.</blockquote>
      <blockquote>What do I mean by “experiential reality”? I mean the universe
        of sensations that you directly experience. [...] From the conventional
        perspective, things are usually believed to exist even when you no
        longer experience them directly, and are thus inferred to exist with
        only circumstantial evidence to be relatively stable entities. [...] For
        our day-to-day lives, this assumption is functional and adequate.</blockquote>
      <blockquote>For example, you could close your eyes, put down this book or
        device, and then pick it up again where you left it without opening your
        eyes. From a pragmatic point of view, this book was where you left it
        even when you were not directly experiencing it. However, when doing
        insight practices, it just happens to be much more useful to assume that
        things are only there when you experience them and not when you don’t.
        Thus, the gold standard for reality when doing insight practices is the
        sensations that make up your reality in that instant. Sensations that
        are not there at that time are not presumed to exist, and thus only
        sensations arising in that instant do exist, with “exist” clearly being
        a problematic term, given how transient sensations are.</blockquote>
      <blockquote>In short, most of what you assume as making up your universe
        doesn’t exist most of the time, from a purely sensate point of view.
        This is exactly, precisely, and specifically the point. [...] sensations
        arise out of nothing, do their thing, and vanish utterly. Gone. Entirely
        gone. </blockquote>
      <p>In Ingram’s terms, people subconsciously assume that if a person in a
        picture has a red hat, then the person in the picture is going to keep
        having a red hat. Also, if the person in the picture has a green hat,
        they probably also had a green hat when you last looked at them. This
        kind of an assumption is often pragmatically useful, and may even be a
        true claim about the world, for as long as the image you are looking at
        is not being manipulated by researchers who keep changing subtle
        details. But it is not an accurate model of how your own mind functions.</p>
      <h2 id="Consciousness_as_an_FBI_report">Consciousness as an FBI report</h2>
      <p>In <span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/x4n4jcoDP7xh5LWLq/book-summary-consciousness-and-the-brain">a
              previous article</a></span></span>, I mentioned that according to
        neuroscientist Stanislas Dehaene, one of the functions of consciousness
        is for subsystems in the brain to exchange summaries of their
        conclusions. He offered the analogy of the US president being briefed by
        the FBI. The FBI is a vast organization, with thousands of employees:
        they are constantly shifting through enormous amounts of data and
        forming hypotheses about topics with national security relevance. But it
        would be useless for the FBI to present to the president every single
        report collected by every single field agent, as well as every analysis
        compiled by every single analyst in response. Rather, the FBI needs to
        internally settle on some overall summary of what they believe is going
        on, and then present that to the President, who can then act based on
        the information. Similarly, Dehaene suggests that consciousness is a
        place where different brain systems can exchange summaries of their
        models, and to integrate conflicting evidence in order to arrive to an
        overall conclusion.</p>
      <p>In a similar way, it’s usually not necessary for the brain to keep a
        conscious track of every little detail in an image. Rather, sensory
        information comes in, and subsystems responsible for processing it
        broadcast a summary of what they consider important about it. If you
        look at a painting, a general summary of its contents will be produced
        and maintained in consciousness, while minor details like the color of
        someone’s hat won’t be recorded unless a person had a particularly
        important reason to look at it. (That would be the equivalent of the FBI
        including a field agent’s random observations in a report to the
        president. They’re very unlikely to include those unless they are <em>really</em>
        important.)</p>
      <p>This is particularly noticeable when learning to draw: as Raemon
        discusses in <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/3ve2pEZS2dBmxbZS2/drawing-less-wrong-observing-reality">Drawing
                Less Wrong: Observing Reality</a></span></span></u>:</p>
      <blockquote>When you look at a person, what you perceive is not a series
        of shapes and colors that correspond to what's there, but rather a bunch
        of hastily constructed symbols that convey the information that the
        brain thinks is important. If you haven't rewired your brain for
        drawing, then "important" questions do not include "<em>Is that elbow
          angled at 90 degrees or 75?</em>" or "<em>Where are the eyes in
          relation to the top of the head?</em>" Instead, what you usually care
        about are things like "is this person happy, or angry?" and the
        information that gets recorded is a little tag that says "Smiling" with
        a vague curving-upwards-line symbol accompanying it.</blockquote>
      <blockquote>A large chunk of the information we usually need has to do
        with the face. This plays a role in two common biases that are
        near-universal in inexperienced artists:</blockquote>
      <blockquote>-Drawing the head much larger than it actually is, compared to
        the rest of the body</blockquote>
      <blockquote>-Drawing the "face" (i.e. everything between the eyebrows and
        mouth) as if they took up the entire head rather than the bottom half.
        Practically everything above the eyebrows conveys no relevant
        information, so it's just ignored.</blockquote>
      <blockquote>Your brain has a mental model of what a human is "supposed" to
        look like, and that model is wrong. You can see major gains in drawing
        capability just by learning the "ideal" proportions of a human being. </blockquote>
      <p>The relation of this to impermanence is that observing the contents of
        your mind lets you notice just how little sense data is actually used,
        and how quickly it vanishes. Returning to Daniel Ingram:</p>
      <blockquote>We are typically quite sloppy about distinguishing between
        physical and mental sensations (memories, mental images, and mental
        impressions of other physical or mental sensations). These two kinds of
        sensations alternate, one arising and passing and then the other arising
        and passing, in a quick but perceptible fashion. Being clear about
        exactly when the physical sensations are present will begin to clarify
        their slippery counterparts—flickering mental impressions—that help
        co-create the illusion of continuity, stability, or solidity. [...]</blockquote>
      <blockquote>Each one of these sensations (the physical sensation and the
        mental impression) arises and vanishes completely before another begins,
        so it is possible to sort out which is which with relatively stable
        attention dedicated to consistent precision and to not being lost in
        stories. This means that the instant you have experienced something, you
        can know that it isn’t there anymore, and whatever is there is a new
        sensation that will be gone in an instant. There are typically many
        other momentary sensations and impressions interspersed with these, but
        for the sake of practice, this is close enough to what is happening to
        be a good working model.</blockquote>
      <p>Ingram suggests that between physical sensations, there are mental
        sensations which “fill in the gaps”, and which prevent people from
        noticing that the original physical sensations only come in
        sporadically. As people become more adept at meditation practices such
        as following the breath, they may come to notice that a large part of
        their time has been spent on following <em>a</em> <em>thought about
          the breath</em>, rather than <em>the breath itself</em>: and far less
        sensory information about the breath actually comes to consciousness
        than they assumed.</p>
      <p>In an <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/mELQFMi9egPn5EAjK/my-attempt-to-explain-looking-insight-meditation-and">earlier
                article on insight meditation</a></span></span></u> I gave
        another example about these kinds of mental sensations. I mentioned a
        time when I was doing concentration meditation, using an app that played
        the sound of something hitting a woodblock, 50 times per minute. As I
        was concentrating on listening to the sound, I noticed that what had
        originally been just one thing in my experience - a discrete sound event
        - was actually composed of many smaller parts. The beginning and end of
        the sound were different, so there were actually two sound sensations;
        and there was a subtle visualization of something hitting something
        else; and a sense of motion accompanying that visualization. I had not
        previously even been fully aware that my mind was automatically creating
        a mental image of what it thought that the sound represented.</p>
      <p>Continuing to observe those different components, I became more aware
        of the fact that my visualization of the sound changed over time and
        between meditation sessions, in a rather arbitrary way. Sometimes my
        mind conjured up a vision of a hammer hitting a rock in a dwarven mine;
        sometimes it was two wooden sticks hitting each other; sometimes it was
        drops of water falling on the screen of my phone.</p>
      <p>Normally, all of this would just be packaged together into a general
        impression of “I’m hearing some sound”. Our raw sense data is made up of
        countless small details and sensations, each arising and passing away in
        rapid succession - but we mostly perceive the high-level summaries,
        which are much more static. This creates an experience of seeing solid
        and discrete objects, and a feeling of there being permanent objects.</p>
      <p>So how <em>does</em> one actually come to see what is happening in
        their mind? </p>
      <p>In <em>The Mind Illuminated</em>, meditation teacher and former
        neuroscientist John Yates (Culadasa) suggests that one way this happens
        is by taking the subsystems responsible for producing such summaries and
        directing them to produce summaries about the content of consciousness.
        The brain already has a subsystem that generates overall summaries of
        what’s going on in your mind; you can train that system to produce more
        detailed reports. Yates calls such summaries <em>introspective
          awareness</em> (discussed in more detail in <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/WYmmC3W6ZNhEgAmWG/a-mechanistic-model-of-meditation">an
                earlier article</a></span></span></u>). </p>
      <h2 id="The_impermanence_of_the_self">The impermanence of the self</h2>
      <p>As I have discussed, consciousness involves a constant competitive
        process, where different subsystems send content to the global
        workspace. At any given time, only one of these pieces of content is
        selected to become the content of consciousness. We might say that there
        has been a “subsystem switch” or a “subsystem swap” when the content of
        consciousness changes from that submitted by one subsystem to that
        submitted by another.</p>
      <p>In normal circumstances, the structure of your mind is such that you
        cannot directly notice the different subsystems getting swapped in and
        out. Your consciousness can only hold one piece of information at a
        time. Suppose that at one moment, you are thinking of your friend, and
        at the next you are thinking of candy. When you think of candy, you are
        no longer aware of the fact that you were thinking of your friend the
        previous moment. You can often <em>infer</em> that a subsystem switch
        has happened, but you can’t actually <em>experience </em>the switch.</p>
      <p>However, if you develop more detailed introspective awareness, the
        stream of your consciousness may include reports such as this:</p>
      <ul>
        <li>Subsystem 1: So I was talking with my friend and she said…</li>
        <li>Subsystem 2: Ooh, candy.</li>
        <li>Awareness subsystem: The train of thought about my friend switched
          to a train of thought about candy right now.</li>
      </ul>
      <p>Subjectively, this feels like becoming aware of the subsystem swapping
        in real time: a thought comes in, while an “afterimage” of the previous
        thought lingers for a brief moment, enough to make you realize that one
        kind of thought has replaced the other. If the trains of thought are
        different enough, the transitions between might feel really sharp and
        distinct.</p>
      <p>You may also notice that you have two or more separate thought streams
        going in parallel, while having had no awareness of the fact. At one
        time you are thinking about your friend, and at the other time you are
        thinking about candy. Despite the fact that these two thought streams
        have kept alternating, maybe switching once every couple of seconds,
        they have been entirely unaware of each other. First the candy is
        everything that is in your mind, then your friend, then the candy again.</p>
      <p>This is not to say that it would normally be impossible to be aware of
        having multiple trains of thought going on. Even without meditative
        training, your brain is constantly producing summaries of what’s
        happening, including summaries of what’s happening in your head. But
        what normally happens is something like having the first train of
        thought, then having the second train of thought, and then having
        general introspective awareness of there being two trains of thought.
        What does not usually happen is that the introspective awareness is
        sharp enough to register the fact that <em>whenever the train of
          thought switches, everything else disappears from consciousness for
          the duration</em>. </p>
      <p>Rather than there being a single observer who experiences all of their
        own thoughts, there are three separate processes, two of them concerned
        with their own issues and a third meta-process keeping a loose record of
        what the two others have been up to.</p>
      <p>A rough analogy would be to a (single-core) computer that keeps <u><span><span><span><a
                  href="https://en.wikipedia.org/wiki/Computer_multitasking">executing
                  multiple different programs in succession</a></span></span></span></u>,
        with the contents of the processor being cleaned out for the next
        program each time the execution switches. As long as everything goes
        smoothly, things will appear to the user as multiple different programs
        being executed at the same time, and the programs themselves will be
        unaware of the other programs. Yet, a sufficiently fine-grained trace of
        the different processes will reveal that only one has been running at a
        time. (Though unlike in this analogy, mental subsystems do keep running
        even when “swapped out”; they just don’t have write access to
        consciousness during that time.)</p>
      <p>By developing sufficient detail, another thing that can be noticed is
        that the sense of self is actually only present a part of the time. As
        discussed in previous posts [<u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/W59Nb72sYJhMJKGB8/a-non-mystical-explanation-of-no-self-three-characteristics">1</a></span></span></u>,
        <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/h2xgbYBNP4dLharg4/on-the-construction-of-the-self">2</a></span></span></u>],
        the experience of a self is basically a piece of data - a <em>narrative</em>
        which is sometimes experienced and sometimes not. That is, it is another
        high-level summary of what is happening - “I am doing this thing” -
        constructed from lower-level data. (<u><span><span><a class="CommentLinkPreviewWithComment-link"
                href="https://www.lesswrong.com/posts/h2xgbYBNP4dLharg4/on-the-construction-of-the-self?commentId=rtutmz8Lb5F8dnfbf">In
                a comment</a></span></span></u>, Vanessa Kosoy suggested that
        the experience of a self is an explanation of <em>why</em> the person
        is doing things, constructed for social purposes and to be able to
        justify your behavior afterwards. This sounds plausible to me.)</p>
      <p>That means that the content of your consciousness may be something
        like:</p>
      <ul>
        <li>Time 1: The sight of a bird outside the window.</li>
        <li>Time 2: The thought “there’s a bird over there”.</li>
        <li>Time 3: The experience of typing on a keyboard.</li>
        <li>Time 4: The sound of a car outside.</li>
        <li>Time 5: A mental image of a car.</li>
        <li>Time 6: A sense of being someone who sees the bird and hears the
          car, while typing on a keyboard.</li>
      </ul>
      <p>… that is, normally you may experience there being a constant,
        permanent self which feels like <em>what you really are</em>. But in
        fact, during a large part of your conscious experience, that sense of
        self may simply not be there at all. Normally this might be impossible
        to detect due to what’s called the <u><span><span><span><a href="https://plato.stanford.edu/entries/introspection/notes.html">refrigerator
                  light illusion</a></span></span></span></u>: the light in a
        refrigerator turns on whenever you open the door, so it seems to you to
        always be on. Likewise, whenever you ask “do I experience a sense of
        self right now”, that question <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/W59Nb72sYJhMJKGB8/a-non-mystical-explanation-of-no-self-three-characteristics#The_self_as_a_tool_for_planning">references
                and activates</a></span></span></u> a self-schema, meaning that
        the answer is always “yes”. It is only by developing introspective
        awareness that records <em>all</em> mental content, without needing to
        make reference to a self, that you can come to notice the way in which
        your self constantly appears and disappears.</p>
      <p>It is worth noting that coming to experience this may feel very
        frightening. Psychologist and meditation teacher Ron Crouch <u><span><span><span><a
                  href="https://alohadharma.com/2011/06/12/the-dark-night/">describes
                  one way that it can go</a></span></span></span></u>:</p>
      <blockquote>What is actually happening, down deep, is that as your
        attention is syncing up with the dissolution of phenomena you are
        finding that there is nothing in experience that the sense of “me” can
        hold onto as stable and permanent. It just can’t get any footing. You do
        not realize it at a cognitive level, but you are getting a deep insight
        into the impermanence of all phenomena, and along with that, into the
        impermanence of the self. This is something that is terrifying to one’s
        very roots. Needles to say this initial stage can be a great source of
        distress and people can become stuck here for some time if they do not
        have good guidance.</blockquote>
      <p>We might think the distress follows from the mind’s underlying
        assumption that the self must be something like a permanent object.
        Whenever one has checked for the presence of the self, it has been
        there: thus, it is something that persists uninterrupted over time
        (except maybe in sleep). Now it - or something that resembles what it
        used to be - suddenly keeps vanishing and reappearing. Does that mean
        that you are dying?</p>
      <p>Eventually, given enough further practice, the mind readjusts and
        revises its models. Continuity of consciousness does not mean
        uninterrupted continuity of self after all; the self is as impermanent
        as any other sensory experience. Nothing here to see, move along now.</p>
      <h2 id="Impermanence_and_unsatisfactoriness">Impermanence and
        unsatisfactoriness</h2>
      <p>One aspect of craving is <em>clinging, </em>a kind of repeated <u><span><span><a
                class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/gvXFBaThWrMsSjicD/craving-suffering-and-predictive-processing-three">craving</a></span></span></u>.
        The mind notices a pleasant or unpleasant sensation, and then tries to
        keep the pleasant sensations in consciousness and the unpleasant
        sensations out of consciousness. This may feel like you are trying to
        “freeze” the content of consciousness into a particular, pleasurable
        slice of experience.</p>
      <p>In <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/r6kzvdia4S8TKE6WF/from-self-to-craving-three-characteristics-series">an
                earlier post</a></span></span></u>, I gave a list of examples
        about craving; this is also a good list of examples to use for clinging,
        so I’ll repeat it here:</p>
      <ul>
        <li>It is morning and your alarm bell rings. You should get up, but it
          feels nice to be sleepy and remain in bed. You want to hang onto those
          pleasant sensations of sleepiness for a little bit more.</li>
        <li>You are spending an evening together with a loved one. This is the
          last occasion that you will see each other in a long time. You feel
          really good being with them, but a small part of you is unhappy over
          the fact that this evening will eventually end.</li>
        <li>You are at work on a Friday afternoon. Your mind wanders to the
          thought of no longer being at work, and doing the things that you had
          planned to do on the weekend. You would prefer to be done with work
          already, and find it hard to stay focused as you cling to the thoughts
          of your free time.</li>
        <li>You are single and hanging out with an attractive person. You know
          that they are not into you, but it would be so great if they were. You
          can’t stop thinking about that possibility, and this keeps distracting
          you from the actual conversation.</li>
        <li>You are in a conversation with several other people. You think of a
          line that would be a really good response to what someone else just
          said. Before you can say it, somebody says a thing, and the
          conversation moves on. You find yourself still thinking of your line,
          and how nice it would have been to get to say it.</li>
        <li>You are playing a game of chess. You see an opportunity to make a
          series of movies that looks like it would win the game for you. You
          get so focused on the sequence of moves that would bring you a
          victory, that you don’t notice that your opponent could also respond
          in a way that would ruin the entire plan.</li>
        <li>You had been planning on going to a famous museum while on your
          vacation, but the museum turns out to be temporarily closed at the
          time. You keep thinking about how much you had been looking forward to
          it. </li>
      </ul>
      <p>What is essentially going on, is the craving trying to <em>fight
          against impermanence</em>. Taking the example of being sleepy and in
        bed: there is the sensation of sleepiness and a feeling of pleasure; <em>and</em>
        that annoying thought which keeps saying that you really need to get up
        soon... and the craving wants that pleasant sleepiness <em>back </em>and
        <em>stable</em>, damnit. If only it would focus on the sleepiness
        enough, maybe that annoying reminder would go away...</p>
      <p>This contributes to the loop where the mind sees craving as necessary
        for well-being: phenomena won’t stabilize in consciousness by
        themselves, and craving takes actions to make them more stable. Whenever
        it is unsuccessfully trying to do so, there is discomfort; when it
        succeeds in getting the pleasant thing to become the object of
        consciousness (if only for a moment), there is less discomfort (if only
        for a moment). Now, that discomfort is being generated <em>by the
          craving itself</em>, so it could also be eliminated by dropping the
        craving… but the system does not notice that.</p>
      <p>Nor does it notice that following the craving does not lead to
        consistent happiness. Of course, we may <em>intellectually</em>
        understand that there’s no single thing that would make us permanently
        and eternally happy. But at the subsystem level, each source of craving
        is based on a schema that states something like:</p>
      <ul>
        <li>If I get the thing I am craving, things will feel satisfying.</li>
      </ul>
      <p>When the subsystem related to that goal is active, this is the schema
        which will be active in the person’s mind. If you are hungry for food,
        you only think about how food will bring relief to your discomfort.
        Intellectually, you may know that soon afterwards you will start wanting
        something else - but the assumption that your mind is operating from, is
        that getting the food will bring contentment. And that assumption is
        correct! Recall that unsatisfactoriness is actually <span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/posts/gvXFBaThWrMsSjicD/craving-suffering-and-predictive-processing-three">caused
              <em>by</em> craving</a></span></span>. So getting the food <em>will</em>
        make the craving for it go away - until the next craving pops up, which
        is likely to happen very soon.</p>
      <p>This has the consequence that each <em>individual </em>craving may
        have its prediction confirmed. The craving for food correctly predicts
        that food will bring satisfaction from that craving. The craving to look
        at the phone while you eat correctly predicts that looking at the phone
        will bring satisfaction from that craving. The craving to go watch
        pictures of attractive naked people after eating correctly predicts that
        going to watch pictures of attractive naked people will bring
        satisfaction from that craving… while the overall system remains in a
        near-constant state of craving that just keeps changing its target.</p>
      <p>In the paper <em>Suffering</em> <span><span><span><a href="https://paperpile.com/c/YK1AjI/YaFw">(</a></span></span></span><u><span><span><span><a
                  href="https://www.blogs.uni-mainz.de/fb05philosophie/files/2013/04/Metzinger_suffering_penultimate.pdf">Metzinger,
                  2016</a></span></span></span></u><span><span><span><a href="https://paperpile.com/c/YK1AjI/YaFw">)</a></span></span></span>,
        Thomas Metzinger reports on an “experience sampling” experiment, where
        messages were sent to people’s phones at random times, asking them
        whether they felt that their current experience would feel worth
        reliving:</p>
      <blockquote>For many, the result was surprising: the number of positive
        conscious moments per week varied between 0 and 36 [out of 70], with an
        average of 11.8 or almost 31 per cent of the phenomenological samples,
        while at 69 per cent a little more than two thirds of the moments were
        spontaneously ranked as not worth reliving.</blockquote>
      <p>Metzinger notes that one cannot generalize from these results to the
        general population: this was a small, unreplicated pilot study done with
        a highly selected group (philosophy students). But as he also notes,
        what <em>is</em> remarkable is that <em>nearly all</em> of the
        participants were surprised by their own results - they had expected
        many more moments to feel pleasurable. He speculates that human
        motivation may depend on systematic self-deception: if a person valued
        positive experiences but noticed that most of their experience was
        actually unpleasant, they might become paralyzed.</p>
      <p>And it does seem that increased awareness of the impermanence of
        satisfaction helps reduce craving. I like to think of each individual
        craving as a form of a <em>hypothesis</em>, in the <u><span><span><a class="PostLinkPreviewWithPost-link"
                href="https://www.lesswrong.com/posts/gvXFBaThWrMsSjicD/craving-suffering-and-predictive-processing-three">predictive
                processing</a></span></span></u> sense where hypotheses drive
        behavior by seeking to prove themselves true. For example (<u><span><span><span><a
                  href="https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00151/full">Friston
                  et al. 2012</a></span></span></span></u>), your visual system
        may see someone's nose and form the hypothesis that "the thing that I'm
        seeing is a nose, and a nose is part of a person's face, so I'm seeing
        someone's face". That contains the prediction "faces have eyes next to
        the nose, so if I look slightly up and to the right I will see an eye,
        and if I look left from there I will see another eye"; it will then seek
        to confirm its prediction by making you look at those spots and verify
        that they do indeed contain eyes.</p>
      <br>
      <div style="text-align: center;"><span> </span>
        <figure><img src="A%20non-mystical%20explanation%20of%20insight%20meditation%20and%20the%20three%20characteristics%20of%20existence_files/saccade.png"
            class="draft-image center" style="width:68%"></figure>
      </div>
      <span> </span></div>
    <p><em>Eye movements seeking to confirm the hypotheses of “I am seeing a
        face”. From <u><span><span><span><a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2012.00151/full">Friston,
                  Adams, Perrinet &amp; Breakspear 2012</a></span></span></span></u>.</em></p>
    <p>Normally, each craving is successfully proving true the hypothesis of
      "pursuing this craving will cause satisfaction"… but included in that
      prediction is not only a claim that satisfying this craving will bring
      momentary satisfaction. As the hypothesis is not modeling events that
      happen after it is satisfied, there is an implied claim that this will
      bring <em>lasting </em>satisfaction.</p>
    <p>If the mind-system develops increased awareness of the way repeated
      craving seems to just lead to a constant state of discomfort, then under
      the right conditions it may consider the hypotheses in those cravings
      falsified and discard them. </p>
    <h2 id="Fighting_against_a_sensation_as_assuming_its_permanence">Fighting
      against a sensation as assuming its permanence</h2>
    <p>Another thing that is happening is the subsystems failing to notice how
      fighting against a sensation actually helps <em>keep</em> it in
      consciousness, and how the sensation might actually fall away <em>on its
        own</em> if it was not being fought against. </p>
    <p>Suppose that you are feeling stressed out over something, and a craving
      is activated to get rid of the feeling of stress. This involves sending
      into consciousness a plan for getting rid of the sensation of stress,
      which needs to <em>make reference to the sensation of stress</em>. This
      tends to redirect <em>more</em> attention towards the sensation of
      stress, strengthening the signal associated with it… and because
      sensations are normally impermanent and tend to easily vanish, this may
      help keep it in consciousness whereas it would otherwise have disappeared
      on its own. </p>
    <p>In general, craving often operates under the assumption that unpleasant
      sensations are permanent: that is, they will persist in consciousness
      until actively resisted. And certainly it is true that not <em>all</em>
      unpleasant sensations will just disappear if you stop feeding them with
      attention. But even then, redirecting attention into a struggle against
      them may <u><span><span><a class="PostLinkPreviewWithPost-link" href="https://www.lesswrong.com/posts/rD57ysqawarsbry6v/attention-control-is-critical-for-changing-increasing">actively
              make them stronger</a></span></span></u>.</p>
    <p>If one develops sufficient introspective awareness, they may come to
      experience this directly. They will notice a neutral sensation, a negative
      sensation, another neutral sensation, then the aversion to the negative
      sensation… and notice there are actually quite a few neutral sensations,
      during which the negative sensation does not bother them at all. This
      helps notice that struggling against discomfort is actually not <em>necessary</em>
      for being free of discomfort; one is free of discomfort a large part of
      the time already.</p>
    <h2 id="Impermanence_as_vibration">Impermanence as vibration</h2>
    <p>No discussion of impermanence would be complete without touching upon the
      topic of “vibrations”. Recall that according to the predictive processing
      model, the brain is composed of layers prediction machinery. A given layer
      can receive sensory information from a lower layer, and from the higher
      layer predictions of what that information <em>should</em> look like. For
      purposes of prediction, each layer is trying to form <em>models</em> of
      what it expects to see. </p>
    <p>Rather than sense information primarily “flowing up” from the sense
      organs, the brain keeps making guesses of what it <em>expects</em> to
      see. These expectations are sent “down to the senses”, with the brain
      using the sense data to <em>check</em> its assumptions and correcting for
      any mismatches. Mismatches that seem small enough may be ignored and
      explained away as noise.</p>
    <p>One possible model is that the sensory information from the lower levels
      represents stable, permanent objects. As has been noted, this assumption
      is often a useful and correct one for predicting how the world behaves, so
      the system begins to assume it… ignoring the fact that sensory data is
      actually coming <em>in pulses</em> rather than constantly. </p>
    <p>When one’s consciousness starts dropping some of the mental impressions
      that normally “fill in the gaps”, it may lead to an experiential quality
      of reality “vibrating”. Here is how <u><span><span><a class="PostLinkPreviewWithPost-link"
              href="https://www.lesswrong.com/s/sznhbtAmucbACzS24/p/QjoTFHzvrxQg9A6j3">DavidM
              describes this</a></span></span></u>:</p>
    <blockquote>A meditator practicing in this style will eventually find that
      their experience is not static, but 'vibrates' or fluxes in a peculiar way
      over extremely short periods of time (fractions of a second). For an
      explanation by analogy, imagine a set of speakers playing music without
      dynamic variation; if a person rapidly turns the volume knob in the
      pattern off-low-high-low-off, the amplitude of the music will flux over
      time. Similarly, a meditator practicing in this style finds that the
      components of experience are not static, but fluctuate rapidly from
      nonexistent to existent and back again. N.B. This has nothing to do with
      the fact that the contents of experience are constantly changing. Rather,
      apparently static objects (e.g. an unchanging white visual field) turn out
      to be in flux.</blockquote>
    <p>For the most part, the hypothesis of “sensory data represents permanent
      objects” has turned out to deliver good results, so normally any gaps in
      the data will be automatically “filled in” by the model, as they are
      assumed to be meaningless noise. As a result, a “neural autocompletion
      feature” can create an impression of closely observing sensory data, even
      when sensory data is actually sparse and the impression of it is mostly
      fabricated on the basis of a few data points.</p>
    <p>For as long as the sensed data deviates only a little from the expected,
      the deviation is treated as noise and ignored; but once the deviation
      crosses some critical threshold, it is picked up and registered as
      surprising. If one intentionally goes looking for vibrations, then one is
      trying to pick up finer and finer distinctions in the sense data. This
      forces the system to pay attention to minor patterns that would otherwise
      have been treated as meaningless noise. That causes it to notice
      discrepancies between the higher-level model’s prediction of “solid stream
      of sense data” and the sensory experiences that are coming in as pulses.
      This leads to an awareness of vibrations, and more generally insight into
      how the brain fills in data which is not actually there.</p>
    <p>On the other hand, I have also heard reports of people finding vibrations
      without explicitly even looking at sensory details, in contexts such as
      doing loving-kindness meditation. I am confused about what is going on
      there and don’t know how to explain it. This is also an area that I have
      personally investigated relatively little.</p>
    <h1>Notes</h1>
    <h2>Sources</h2>
    <ul>
      <li> <a href="https://www.lesswrong.com/posts/Mf2MCkYgSZSJRz5nM/a-non-mystical-explanation-of-insight-meditation-and-the">A
          non-mystical explanation of insight meditation and the three
          characteristics of existence: introduction and preamble</a></li>
    </ul>
    <ul>
      <li><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/W59Nb72sYJhMJKGB8">A
          non-mystical explanation of "no-self" (three characteristics series)</a></li>
    </ul>
    <ul>
      <li><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/gvXFBaThWrMsSjicD">Craving,
          suffering, and predictive processing (three characteristics series</a></li>
    </ul>
    <ul>
      <li><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/r6kzvdia4S8TKE6WF">From
          self to craving (three characteristics series)</a></li>
    </ul>
    <ul>
      <li><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/h2xgbYBNP4dLharg4">On
          the construction of the self</a></li>
    </ul>
    <ul>
      <li><a href="https://www.lesswrong.com/s/ZbmRyDN8TCpBTZSip/p/T8gD9mRDHnb2gyn9N">Three
          characteristics: impermanence</a></li>
    </ul>
    <div>
      <p></p>
      <h2>About this e-book</h2>
      <p>This e-book was created by <a href="https://atrahhdis.github.io/">atrahhdis</a>
        using <a href="https://en.wikipedia.org/wiki/Markdown">markdown</a>, <a
          href="https://pandoc.org/">pandoc</a> and <a href="https://calibre-ebook.com/">calibre</a>.</p>
      <h2>Version</h2>
      <p> </p>
      <p>V 1.01 - 2020-09-30</p>
    </div>
    <p></p>
    <p></p>
    <p></p>
    <p></p>
    <p></p>
    <p></p>
    <p></p>
  </body>
</html>
